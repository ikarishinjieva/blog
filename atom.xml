<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tac say]]></title>
  <link href="http://ikarishinjieva.github.com/blog/atom.xml" rel="self"/>
  <link href="http://ikarishinjieva.github.com/blog/"/>
  <updated>2014-03-25T22:41:06+08:00</updated>
  <id>http://ikarishinjieva.github.com/blog/</id>
  <author>
    <name><![CDATA[Tac Huang (ikari_shinji@github)]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[golang, cmd会泄露文件句柄]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2014/03/25/go-leak-fd/"/>
    <updated>2014-03-25T22:34:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2014/03/25/go-leak-fd</id>
    <content type="html"><![CDATA[<p>在go中用<code>cmd</code>生成新的process时, 在某些os中(包括linux的某些版本), 父进程的文件句柄会泄露到子进程中, 参看代码</p>

<pre><code>package main

import (
    "fmt"
    "os"
    "os/exec"
)

func main() {
    a, _ := os.OpenFile("1", os.O_CREATE|os.O_RDWR, 0755)
    defer a.Close()
    cmd := exec.Command("sh", "-c", "lsof +D .; sleep 3")
    output, _ := cmd.CombinedOutput()
    fmt.Printf("%v\n", string(output))
}
</code></pre>

<p>得到输出</p>

<pre><code>[root@GroupH-HA-1 tmp]# uname -a
Linux GroupH-HA-1 2.6.18-194.el5xen #1 SMP Tue Mar 16 22:01:26 EDT 2010 x86_64 x86_64 x86_64 GNU/Linux
[root@GroupH-HA-1 tmp]# ./main
COMMAND  PID USER   FD   TYPE DEVICE    SIZE    NODE NAME
bash    4693 root  cwd    DIR  253,0   32768 3506177 .
main    6184 root  cwd    DIR  253,0   32768 3506177 .
main    6184 root  txt    REG  253,0 2250464 3506237 ./main
main    6184 root    3u   REG  253,0       0 3506238 ./1
sh      6189 root  cwd    DIR  253,0   32768 3506177 .
sh      6189 root    3u   REG  253,0       0 3506238 ./1
lsof    6190 root  cwd    DIR  253,0   32768 3506177 .
lsof    6191 root  cwd    DIR  253,0   32768 3506177 .
</code></pre>

<p>可以看到<code>./1</code>的文件句柄泄漏到了<code>sh -c</code>中, 目前为止没有特别好的解决方案</p>

<p>参看<a href="https://code.google.com/p/go/issues/detail?id=2603">此处bug描述</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[golang, windows和linux上的文件锁]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2014/03/20/go-file-lock/"/>
    <updated>2014-03-20T22:43:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2014/03/20/go-file-lock</id>
    <content type="html"><![CDATA[<p>直接上代码, <code>LockFile</code>可以获得一个文件的独占权, 或阻塞等待</p>

<h4>linux</h4>

<pre><code>func LockFile(file *os.File) error {
    return syscall.Flock(int(file.Fd()), syscall.LOCK_EX)
}
</code></pre>

<h4>windows</h4>

<pre><code>func LockFile(file *os.File) error {
    h, err := syscall.LoadLibrary("kernel32.dll")
    if err != nil {
        return err
    }
    defer syscall.FreeLibrary(h)

    addr, err := syscall.GetProcAddress(h, "LockFile")
    if err != nil {
        return err
    }
    for {
        r0, _, _ := syscall.Syscall6(addr, 5, file.Fd(), 0, 0, 0, 1, 0)
        if 0 != int(r0) {
            break
        }
        time.Sleep(100 * time.Millisecond)
    }
    return nil
}
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[推荐下我修改的gen]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2014/03/02/gen/"/>
    <updated>2014-03-02T21:29:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2014/03/02/gen</id>
    <content type="html"><![CDATA[<p><a href="http://clipperhouse.github.io/gen/"><code>gen</code></a>是go的代码生成器, 提供类似于<code>underscore</code>的函数集.</p>

<p>尝试将<code>gen</code>用在项目上,发现不太方便,对源码做了如下两个修改, 修改后的代码在<a href="https://github.com/ikarishinjieva/gen">这里</a>:</p>

<h4>1. 支持条件编译</h4>

<p>go提供了条件编译,根据<code>GOOS</code>和<code>GOARCH</code>进行交叉编译,也可以利用<a href="http://golang.org/cmd/go"><code>build tags</code></a>自定义条件编译</p>

<p>修改前可能碰到的问题是存在<code>a_linux.go</code>和<code>a_windows.go</code>, 分别定义一个函数<code>A</code>的两个版本. 调用<code>gen</code>时会报错:<code>A</code>不可以重复定义</p>

<p>这个修改已经被merge回原分支</p>

<h4>2. 对于import的其它包, 支持分析其源码</h4>

<p>设想一个场景, 存在<code>root/A</code>和<code>root/B</code>两个包, <code>root/B</code> import <code>root/A</code></p>

<p>在<code>root/B</code>上调用<code>gen</code>, <code>gen</code>会分析import关系, 找到并分析<code>root/A</code></p>

<p>在修改之前, 由于<code>gen</code>只使用了<code>types.Check</code>, 默认只会使用<code>gcimport</code>,只分析<code>root/A</code>编译好的pkg(<code>.a</code>文件), 而不包括<code>root/A</code>的源码.</p>

<p>也就是说对于所有依赖, 必须都保证其跑过<code>go install</code>, 才能在下游模块使用<code>gen</code>. 这个并不方便</p>

<p>做的修改是使用<code>go.tools/importer</code>代替<code>gcimporter</code>, 既可以分析编译好的pkg, 又可以分析源码</p>

<p>不过这个修改的代价是分析的时间会比较长</p>

<p>这个修改尚未被原分支接受</p>

<h4>3. <code>types</code>源码分析的一个问题</h4>

<p>以下代码在分析源码时报错, 但编译时是通过的</p>

<pre><code>c := make(chan os.Signal, 1)
signal.Notify(c, syscall.SIGTTIN)
</code></pre>

<p>分析时报的错是</p>

<pre><code>cannot pass argument c (variable of type chan os.Signal) to parameter of type chan&lt;- os.Signal
</code></pre>

<p>目前无解, 但结论是用<code>types</code>包进行的源码分析结果和编译时的略有差异</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GO exec.command.Wait 执行后台程序,在重定向输出时卡住]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2014/02/22/go-exec-command-block-when-redirect-stdout/"/>
    <updated>2014-02-22T10:30:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2014/02/22/go-exec-command-block-when-redirect-stdout</id>
    <content type="html"><![CDATA[<p>在GO上发现以下现象</p>

<pre><code>c := exec.Command("sh", "-c", "sleep 100 &amp;")
var b bytes.Buffer
c.Stdout = &amp;b

if e := c.Start(); nil != e {
    fmt.Printf("ERROR: %v\n", e)
}
if e := c.Wait(); nil != e {
    fmt.Printf("ERROR: %v\n", e)
}
</code></pre>

<p>这个代码会一直等到<code>sleep 100</code>完成后才退出, 与常识不符.</p>

<p>但去掉Stdout重定向后, 代码就不会等待卡住</p>

<pre><code>c := exec.Command("sh", "-c", "sleep 100 &amp;")
if e := c.Start(); nil != e {
    fmt.Printf("ERROR: %v\n", e)
}
if e := c.Wait(); nil != e {
    fmt.Printf("ERROR: %v\n", e)
}
</code></pre>

<p>在运行时打出stacktrace, 再翻翻GO的源代码, 发现GO卡在以下代码</p>

<pre><code>func (c *Cmd) Wait() error {
    ...
    state, err := c.Process.Wait()
    ...
    var copyError error
    for _ = range c.goroutine {
        if err := &lt;-c.errch; err != nil &amp;&amp; copyError == nil {
            copyError = err
        }
    }
    ...
}
</code></pre>

<p>可以看到<code>Wait()</code>在等待Process结束后, 还等待了所有<code>c.goroutine</code>的<code>c.errch</code>信号. 参看以下代码:</p>

<pre><code>func (c *Cmd) stdout() (f *os.File, err error) {
    return c.writerDescriptor(c.Stdout)
}

func (c *Cmd) writerDescriptor(w io.Writer) (f *os.File, err error) {
    ...
    c.goroutine = append(c.goroutine, func() error {
        _, err := io.Copy(w, pr)
        return err
    })
    ...
}
</code></pre>

<p>重定向<code>stdout</code>时, 会添加一个监听任务到<code>goroutine</code> (<code>stderr</code>也是同理)</p>

<p>结论是由于将<code>sleep 100</code>放到后台执行, 其进程<code>stdout</code>并没有关闭, <code>io.Copy()</code>不会返回, 所以会卡住</p>

<p>临时的解决方法就是将后台进程的<code>stdout</code>和<code>stderr</code>重定向出去, 以下代码不会卡住:</p>

<pre><code>c := exec.Command("sh", "-c", "sleep 100 &gt;/dev/null 2&gt;/dev/null &amp;")
var b bytes.Buffer
c.Stdout = &amp;b

if e := c.Start(); nil != e {
    fmt.Printf("ERROR: %v\n", e)
}
if e := c.Wait(); nil != e {
    fmt.Printf("ERROR: %v\n", e)
}
</code></pre>

<p>已经报了<a href="https://code.google.com/p/go/issues/detail?id=7378&amp;thanks=7378&amp;ts=1392967848">bug</a></p>

<p>但想不出好的GO代码的修改方案</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[尝试使用mysql plugin将RESET SLAVE后的节点重新恢复成slave]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2014/02/11/try-rollback-master-back-to-slave-by-mysql-plugin/"/>
    <updated>2014-02-11T22:31:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2014/02/11/try-rollback-master-back-to-slave-by-mysql-plugin</id>
    <content type="html"><![CDATA[<p>这几天在尝试为以下场景制作一个mysql plugin, 但是是一个失败的尝试, 在此记录</p>

<pre><code>一对mysql主从节点 M-S, 节点S执行了RESET SLAVE
后来后悔了
在没有数据通过非replication的渠道写入S的条件下, 想让S和M重新恢复成一对主从
</code></pre>

<p>关键点是S能将<code>RESET SLAVE</code>时S的<code>Exec_Master_Log_Pos</code>和<code>S binlog pos</code>记录下来</p>

<p>尝试了以下几种方案:</p>

<h5>1. 调用者在<code>RESET SLAVE</code>时手工记录, 不需要制作插件</h5>

<hr />

<h5>2. Audit plugin.</h5>

<p>Mysql的Audit plugin可以审计大部分mysqld经手的SQL, 包括<code>RESET SLAVE</code>.</p>

<p>但Audit plugin是在每个SQL之后才会调用. 在<code>RESET SLAVE</code>时S上master_info会被清理, 即<code>Exec_Master_Log_Pos</code>的信息在调用Audit plugin已经丢失</p>

<hr />

<h5>3. Replication plugin (<code>after_reset_slave</code>)</h5>

<p>Replication plugin (参看mysql semisync的源码), 在slave端提供了<code>Binlog_relay_IO_observer</code>, 贴个Mysql源码方便理解</p>

<pre><code>/**
    Observes and extends the service of slave IO thread.
 */
 typedef struct Binlog_relay_IO_observer {
   uint32 len;

   /**
      This callback is called when slave IO thread starts

      @param param Observer common parameter

      @retval 0 Sucess
      @retval 1 Failure
   */
   int (*thread_start)(Binlog_relay_IO_param *param);

   /**
      This callback is called when slave IO thread stops

      @param param Observer common parameter

      @retval 0 Sucess
      @retval 1 Failure
   */
   int (*thread_stop)(Binlog_relay_IO_param *param);

   /**
      This callback is called before slave requesting binlog transmission from master

      This is called before slave issuing BINLOG_DUMP command to master
      to request binlog.

      @param param Observer common parameter
      @param flags binlog dump flags

      @retval 0 Sucess
      @retval 1 Failure
   */
   int (*before_request_transmit)(Binlog_relay_IO_param *param, uint32 flags);

   /**
      This callback is called after read an event packet from master

      @param param Observer common parameter
      @param packet The event packet read from master
      @param len Length of the event packet read from master
      @param event_buf The event packet return after process
      @param event_len The length of event packet return after process

      @retval 0 Sucess
      @retval 1 Failure
   */
   int (*after_read_event)(Binlog_relay_IO_param *param,
                           const char *packet, unsigned long len,
                           const char **event_buf, unsigned long *event_len);

   /**
      This callback is called after written an event packet to relay log

      @param param Observer common parameter
      @param event_buf Event packet written to relay log
      @param event_len Length of the event packet written to relay log
      @param flags flags for relay log

      @retval 0 Sucess
      @retval 1 Failure
   */
   int (*after_queue_event)(Binlog_relay_IO_param *param,
                            const char *event_buf, unsigned long event_len,
                            uint32 flags);

   /**
      This callback is called after reset slave relay log IO status

      @param param Observer common parameter

      @retval 0 Sucess
      @retval 1 Failure
   */
   int (*after_reset_slave)(Binlog_relay_IO_param *param);
 } Binlog_relay_IO_observer;
</code></pre>

<p>首先尝试用<code>after_reset_slave</code>, 从函数名字就可以看到会遇到和Audit Plugin相同的问题: 即<code>Exec_Master_Log_Pos</code>的信息在调用时已经丢失</p>

<hr />

<h5>4. Replication plugin (<code>after_reset_slave</code>再尝试, <code>future_group_master_log_pos</code>)</h5>

<p>还不死心, <code>Exec_Master_Log_Pos</code>的数据结构是<code>Relay_log_info.group_master_log_pos</code>, 尽管这个信息在<code>after_reset_slave</code>时已经丢失, 但发现<code>Relay_log_info.future_group_master_log_pos</code>可能是个方向</p>

<p>先解释<code>Relay_log_info.future_group_master_log_pos</code>, 可以参看<code>log_event.cc</code>的这段注释</p>

<pre><code>  /*
    InnoDB internally stores the master log position it has executed so far,
    i.e. the position just after the COMMIT event.
    When InnoDB will want to store, the positions in rli won't have
    been updated yet, so group_master_log_* will point to old BEGIN
    and event_master_log* will point to the beginning of current COMMIT.
    But log_pos of the COMMIT Query event is what we want, i.e. the pos of the
    END of the current log event (COMMIT). We save it in rli so that InnoDB can
    access it.
  */
  const_cast&lt;Relay_log_info*&gt;(rli)-&gt;future_group_master_log_pos= log_pos;
</code></pre>

<p><code>future_group_master_log_pos</code>指向了execute的最后一个transaction的COMMIT event之前, 即<code>future_group_master_log_pos</code> 大部分时间等于 <code>group_master_log_pos - 27</code> (27是COMMIT event的长度)</p>

<p>但仍有例外情况: 如果M执行了<code>FLUSH LOGS</code>, 将log从0001递增到了0002, 此时S上的<code>future_group_master_log_pos</code>会指向0001的最后一个transaction的COMMIT event之前. 但S上的<code>group_master_log_name</code>已经到了0002, 与<code>future_group_master_log_pos</code>不匹配, 会引起异常</p>

<p>(其实此时S上的<code>group_master_log_name</code>也已经置空了, 但可以从内存残片中恢复出文件名)</p>

<p>设想如果对于log_name也有<code>future_group_master_log_name</code>, 那么S可以直接<code>change master</code>到M的<code>future_group_master_log_name</code>和<code>future_group_master_log_pos</code>位置, 可以恢复起M-S主从结构</p>

<hr />

<h5>5. Replication plugin (<code>thread_stop</code>)</h5>

<p>Replication plugin的<code>thread_stop</code>是指Slave IO thread停止时调用, 此时可以拿到<code>Exec_Master_Log_Pos</code>和<code>S binlog pos</code>, 但拿到的<code>S binlog pos</code>没有意义, 因为不能保证Slave SQL thread也停下来了</p>

<hr />

<h5>6. Storage Engine plugin</h5>

<p>这是我最后一根救命稻草, 阅读Mysql源码时注意到以下片段(做了缩减)</p>

<pre><code>int reset_slave(THD *thd, Master_info* mi)
{
    ...
    ha_reset_slave(thd);
    ... //clean memory data
}
</code></pre>

<p><code>reset_slave</code>在清理内存数据前通知了storage engine插件, 这个插件可以获得所有必要信息</p>

<p>但存在一个问题, 即<code>ha_reset_slave</code>仅在Mysql NDB版本中存在, 不具备通用性, 参看宏定义(做了缩减)</p>

<pre><code>#ifdef HAVE_NDB_BINLOG
...
void ha_reset_slave(THD *thd);
...
#else
...
#define ha_reset_slave(a) do {} while (0)
...
#endif
</code></pre>

<hr />

<h4>吐槽和总结</h4>

<p>可以看到Mysql plugin不<strong>太</strong>预留接口, 是仅仅为已知应用场景提供必要接口, 比如<code>Binlog_relay_IO_observer</code>中有<code>after</code>不一定有<code>before</code>. 比较容易控制插件质量, 但插件能做到的非常局限.</p>

<p>以上各种尝试, 归根到底, 只要修改Mysql的一点源码编译一下就可以达到很好的效果, 不需要用插件的方式在Mysql中到处找功能插槽, 但通用性变差.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[编译mysql插件的碰到的问题]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2014/01/28/compile-mysql-plugin/"/>
    <updated>2014-01-28T16:48:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2014/01/28/compile-mysql-plugin</id>
    <content type="html"><![CDATA[<p>最近尝试制作了<a href="https://github.com/ikarishinjieva/mysql_plugin-binlog_dump_list">一个mysql的插件</a>. 对c/c++的编译不熟, 又是第一次尝试做mysql插件, 编译过程中碰到些状况</p>

<p>编写好mysql插件后, 编译成功, 在mysql中安装运行报错: 取了<code>threads</code>中的THD, 其中THD->thread_id值为空</p>

<p>由于是mysql内置的数据结构, 一时没了头绪, 只能通过gdb连上去看看</p>

<p>发现plugin打印出来的thread_id距离THD开头的距离为</p>

<pre><code>tmp=0x3661f80
&amp;tmp-&gt;thread_id=0x36637b0
delta = 0x1830
</code></pre>

<p>而gdb打印出来的距离为</p>

<pre><code>(gdb) p tmp
$1 = (THD *) 0x3661f80
(gdb) p &amp;tmp-&gt;thread_id
$2 = (my_thread_id *) 0x3663878
delta = 0x18F8
</code></pre>

<p>结论很显然, plugin编译的THD结构和mysqld的THD结构不匹配, 即plugin的编译参数和mysqld的编译参数不一样.</p>

<p>当然mysql的文档上只会说一句大意是 &#8221;<strong>编译参数应当设置成一样的</strong>&#8220;的话</p>

<p>其中比较重要的几个编译选项</p>

<ol>
<li>DBUG_ON</li>
<li>SAFE_MUTEX</li>
<li>DBUG_OFF (不设置DBUG_ON并不等于DBUG_OFF)</li>
</ol>


<p>这几个选项会影响当使用mysqld内部数据结构的长度, 不排除还有其他</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[jruby中tcp阻塞时Timeout::timeout失效]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2014/01/08/jruby-bug-tcp-timeout/"/>
    <updated>2014-01-08T23:04:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2014/01/08/jruby-bug-tcp-timeout</id>
    <content type="html"><![CDATA[<h3>问题场景</h3>

<p>首先有一台tcp server, 模拟一个黑洞</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="nb">require</span> <span class="s1">&#39;socket&#39;</span>
</span><span class='line'>
</span><span class='line'><span class="n">tcp_server</span> <span class="o">=</span> <span class="no">TCPServer</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="s2">&quot;0.0.0.0&quot;</span><span class="p">,</span> <span class="mi">6666</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="kp">loop</span> <span class="k">do</span>
</span><span class='line'>     <span class="n">socket</span> <span class="o">=</span> <span class="n">tcp_server</span><span class="o">.</span><span class="n">accept</span>
</span><span class='line'>     <span class="nb">puts</span> <span class="s1">&#39;got conn&#39;</span><span class="o">]</span>
</span><span class='line'>     <span class="c1">#blackhole</span>
</span><span class='line'><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p>然后发起一个connection, 从server接受消息(很显然会阻塞在recv上), 并用<code>Timeout::timeout</code>设置一个超时时间</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="nb">require</span> <span class="s2">&quot;socket&quot;</span>
</span><span class='line'><span class="nb">require</span> <span class="s2">&quot;timeout&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="n">sock</span> <span class="o">=</span> <span class="no">Socket</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="ss">Socket</span><span class="p">:</span><span class="ss">:AF_INET</span><span class="p">,</span> <span class="ss">Socket</span><span class="p">:</span><span class="ss">:SOCK_STREAM</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span><span class='line'><span class="n">addr</span> <span class="o">=</span> <span class="no">Socket</span><span class="o">.</span><span class="n">sockaddr_in</span><span class="p">(</span><span class="mi">6666</span><span class="p">,</span> <span class="s2">&quot;127.0.0.1&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">sock</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">addr</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="ss">Timeout</span><span class="p">:</span><span class="ss">:timeout</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>     <span class="n">sock</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>上面这个场景如果在ruby上跑,5秒后会超时,但如果使用jruby(1.7.6)就会一直处于阻塞</p>

<h3>解决方案</h3>

<p>使用非阻塞<code>recv</code>,可以在jruby上正常运行</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="nb">require</span> <span class="s2">&quot;socket&quot;</span>
</span><span class='line'><span class="nb">require</span> <span class="s2">&quot;timeout&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="n">sock</span> <span class="o">=</span> <span class="no">Socket</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="ss">Socket</span><span class="p">:</span><span class="ss">:AF_INET</span><span class="p">,</span> <span class="ss">Socket</span><span class="p">:</span><span class="ss">:SOCK_STREAM</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span><span class='line'><span class="n">addr</span> <span class="o">=</span> <span class="no">Socket</span><span class="o">.</span><span class="n">sockaddr_in</span><span class="p">(</span><span class="mi">6666</span><span class="p">,</span> <span class="s2">&quot;127.0.0.1&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">sock</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">addr</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="ss">Timeout</span><span class="p">:</span><span class="ss">:timeout</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="k">begin</span>
</span><span class='line'>        <span class="n">sock</span><span class="o">.</span><span class="n">recv_nonblock</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span class='line'>    <span class="k">rescue</span> <span class="ss">IO</span><span class="p">:</span><span class="ss">:WaitReadable</span>
</span><span class='line'>        <span class="no">IO</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">[</span><span class="n">sock</span><span class="o">]</span><span class="p">,</span><span class="kp">nil</span><span class="p">,</span><span class="kp">nil</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
</span><span class='line'>        <span class="k">retry</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h3>猜测</h3>

<p>查看一下ruby <code>timeout.rb</code>的源码</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'>  <span class="k">begin</span>
</span><span class='line'>    <span class="n">x</span> <span class="o">=</span> <span class="no">Thread</span><span class="o">.</span><span class="n">current</span>
</span><span class='line'>    <span class="n">y</span> <span class="o">=</span> <span class="no">Thread</span><span class="o">.</span><span class="n">start</span> <span class="p">{</span>
</span><span class='line'>      <span class="k">begin</span>
</span><span class='line'>        <span class="nb">sleep</span> <span class="n">sec</span>
</span><span class='line'>      <span class="k">rescue</span> <span class="o">=&gt;</span> <span class="n">e</span>
</span><span class='line'>        <span class="n">x</span><span class="o">.</span><span class="n">raise</span> <span class="n">e</span>
</span><span class='line'>      <span class="k">else</span>
</span><span class='line'>        <span class="n">x</span><span class="o">.</span><span class="n">raise</span> <span class="n">exception</span><span class="p">,</span> <span class="s2">&quot;execution expired&quot;</span>
</span><span class='line'>      <span class="k">end</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>    <span class="k">return</span> <span class="k">yield</span><span class="p">(</span><span class="n">sec</span><span class="p">)</span>
</span><span class='line'>  <span class="k">ensure</span>
</span><span class='line'>    <span class="k">if</span> <span class="n">y</span>
</span><span class='line'>      <span class="n">y</span><span class="o">.</span><span class="n">kill</span>
</span><span class='line'>      <span class="n">y</span><span class="o">.</span><span class="n">join</span> <span class="c1"># make sure y is dead.</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>  <span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p>大概看到timeout是起了一个计时线程,超时时向主线程发起exception</p>

<p>猜测是因为jvm的线程模型导致exception不能向阻塞线程提交,但有待验证</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[栽在Go中for的变量]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2013/12/26/go-iterate-variable/"/>
    <updated>2013-12-26T22:13:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2013/12/26/go-iterate-variable</id>
    <content type="html"><![CDATA[<p>我是万没料到自己栽在了go的for上，说多了都是眼泪</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='go'><span class='line'><span class="kd">type</span> <span class="nx">testStruct</span> <span class="kd">struct</span> <span class="p">{</span>
</span><span class='line'>     <span class="nx">no</span> <span class="kt">int</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="kd">func</span> <span class="nx">main</span><span class="p">()</span> <span class="p">{</span>
</span><span class='line'>     <span class="nx">a</span> <span class="o">:=</span> <span class="p">[]</span><span class="nx">testStruct</span><span class="p">{</span><span class="nx">testStruct</span><span class="p">{</span><span class="mi">1</span><span class="p">},</span> <span class="nx">testStruct</span><span class="p">{</span><span class="mi">2</span><span class="p">},</span> <span class="nx">testStruct</span><span class="p">{</span><span class="mi">3</span><span class="p">}}</span>
</span><span class='line'>     <span class="kd">var</span> <span class="nx">p</span> <span class="o">*</span><span class="nx">testStruct</span>
</span><span class='line'>     <span class="k">for</span> <span class="nx">_</span><span class="p">,</span> <span class="nx">i</span> <span class="o">:=</span> <span class="k">range</span> <span class="nx">a</span> <span class="p">{</span>
</span><span class='line'>          <span class="k">if</span> <span class="nx">i</span><span class="p">.</span><span class="nx">no</span> <span class="o">==</span> <span class="mi">2</span> <span class="p">{</span>
</span><span class='line'>               <span class="c1">// o := i</span>
</span><span class='line'>               <span class="c1">// p = &amp;o</span>
</span><span class='line'>               <span class="nx">p</span> <span class="p">=</span> <span class="o">&amp;</span><span class="nx">i</span>
</span><span class='line'>          <span class="p">}</span>
</span><span class='line'>     <span class="p">}</span>
</span><span class='line'>     <span class="nx">fmt</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="nx">p</span><span class="p">.</span><span class="nx">no</span><span class="p">)</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>猜猜看输出是多少？<a href="http://play.golang.org/p/OzkxuYIboc">试试看吧</a></p>

<p>理解起来很容易，<code>p</code>取得是<code>i</code>的地址，而<strong>range循环变量<code>i</code>在每个循环之间都是复用同一个地址</strong></p>

<p>证明一下，<a href="http://play.golang.org/p/b3QFcoh35Q">试试看？</a></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='go'><span class='line'><span class="nx">a</span> <span class="o">:=</span> <span class="p">[]</span><span class="kt">int</span><span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">}</span>
</span><span class='line'><span class="k">for</span> <span class="nx">_</span><span class="p">,</span> <span class="nx">item</span> <span class="o">:=</span> <span class="k">range</span> <span class="nx">a</span> <span class="p">{</span>
</span><span class='line'>     <span class="nx">fmt</span><span class="p">.</span><span class="nx">Printf</span><span class="p">(</span><span class="s">&quot;%p\n&quot;</span><span class="p">,</span> <span class="o">&amp;</span><span class="nx">item</span><span class="p">)</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>虽然很容易理解，也很容易掉坑，尤其for上用<code>:=</code>，那感觉就像js里连续用<code>var</code>，除了第一下剩下的都不好使&#8230;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[对于PaxosLease的个人理解 2]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2013/12/19/paxos-lease-2/"/>
    <updated>2013-12-19T20:19:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2013/12/19/paxos-lease-2</id>
    <content type="html"><![CDATA[<p>在阅读之前，请确定已浏览过<a href="http://ikarishinjieva.github.io/blog/blog/2013/12/19/paxos-lease/">第一篇</a>，并阅读过以下参考文献[1]（最好是阅读过参考文献[2]）</p>

<hr />

<h4>参考文献</h4>

<p>[1]<a href="http://dsdoc.net/paxoslease/index.html">【译】PaxosLease：实现租约的无盘Paxos算法</a></p>

<p>[2] <a href="https://github.com/scalien/keyspace/tree/master/src/Framework/PaxosLease">Keyspace源码</a></p>

<hr />

<p>本篇将讨论以下一些实现PaxosLease中的问题和解决：</p>

<ol>
<li>2PC 两阶段的超时设置</li>
<li>续租困境及解决</li>
<li>Proposer对HighestPromisedProposeId的学习</li>
<li>放弃租约</li>
</ol>


<hr />

<p>假设读者已经从参考文献[1]中熟悉了PaxosLease算法，在所有讨论之前，我们还是先简述一下整个PaxosLease算法，目的来统一一些术语。其中有一些空白，类似于<strong>{1}</strong>，后面的讨论中会将这些空白逐一填满：</p>

<p><strong>1</strong> Proposer A 想要获得租约，生成一个新的ProposeId，组装成一个Prepare Request，并广播给所有Accepter</p>

<p><strong>2</strong> Accepter B收到来自Proposer A的PrepareRequest，检查PrepareRequest中的ProposeId<br/>
若低于Accepter B的HighestPromisedProposeId，则忽略这一PrepareRequest，<strong>{5}</strong><br/>
否则</p>

<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将HighestPromisedProposeId置为PrepareRequest中的ProposeId


<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **{1}**


<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;且向Proposer A反馈Prepare Response，Response中带有Accepter B的AcceptedProposeId（可能为空）<br/>


<p><strong>3</strong> Proposer A收到Accepter B的Prepare Response。<br/>若多数派Accepter返回的PrepareRequest中的AcceptedProposeId都为空，<strong>{2}</strong>，则表示多数派Accepter都可以接受Proposer A的Propose，进入Propose 阶段：</p>

<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Proposer A启动租约定时器β。定时器β超时时，重新启动Prepare阶段


<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Proposer A向多数派广播ProposeRequest<br/>


<p><strong>4</strong> <strong>{6}</strong></p>

<p><strong>5</strong> Accepter B收到来自Proposer A的ProposeRequest，（再次）检查ProposeRequest中的ProposeId</p>

<br/>若低于Accepter B的HighestPromisedProposeId，则忽略这一ProposeRequest


<br/>否则：<br/>将HighestPromisedProposeId置为ProposeRequest中的ProposeId


<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;且将AcceptedProposeId置为ProposeRequest中的ProposeId


<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;且启动定时器γ。定时器γ超时时，将AcceptedProposeId置为0


<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;且向Proposer A反馈ProposeResponse<br/>


<p><strong>6</strong> Proposer A收到Accepter B的ProposeResponse。若Proposer A已收到多数派的ProposeReponse，则Proposer A:</p>

<br/>可以认为自己持有租约，租约到期的时间为定时器β的超时时间，租约到期时需要清理


<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**{4}**


<br/>**{3}**<br/>


<hr />

<h4>这一部分讨论2PC两阶段的超时设置</h4>

<p>PaxosLease的过程引自参考[1]中，可以看到Prepare阶段没有计时器，而在Propose阶段，Proposer和Accepter分别启动定时器β和定时器γ，来表示“Propose阶段在当前节点超时，需要重新启动投票”，或者“租约在当前节点过期，当前节点可以参与新一轮投票”</p>

<p>可以看到这个结论与<a href="http://ikarishinjieva.github.io/blog/blog/2013/12/19/paxos-lease/">上一篇</a>的描述不符，下面来解释原因</p>

<p>在这种设计下，若Prepare阶段有请求丢失，导致Proposer没法获得多数派的反馈，则Prepare阶段会僵死在那里</p>

<p>参考[1]中使用这种设计的原因是参考[1]中仅讨论了一次投票的情景，并不包括如何长期维护投票秩序。作为一个介绍性的文章，这种情景限定有助于读者理解</p>

<p>而实际应用中，我们必须要解决Prepare阶段的僵死情况，即在Prepare阶段也加入定时器（Keyspace中也是这样做的）：<br/>
<strong>{1}</strong> = &#8220;并启动定时器α，时长小于租约时长。α超时时，重新启动Prepare阶段。在节点进入Propose阶段时，取消α计时&#8221;</p>

<hr />

<h4>续租困境及解决</h4>

<p>在实际应用中，希望长时间维持一个节点master的身份，而不希望master在集群里换来换去，那么当前持有租约的节点就希望能成功续租</p>

<p>先介绍续租的实现，参考[1]中提到“如果多数派响应了空的提案或是 <em>已存在提案</em> （即这个提案中的该请求者的租约还没有过期），它可以再次提议自己为租约的持有者”，相应的我们在过程中做出修改：<br/>
<strong>{2}</strong> = &#8220;或PrepareRequest中的AcceptedProposeId=Proposer A的leaseProposeId&#8221;<br/>
<strong>{3}</strong> = &#8220;置leaseProposeId为当前的proposeId&#8221;<br/>
<strong>{4}</strong> = &#8220;置leaseProposeId为0&#8221;<br/></p>

<p>续租实现后，测试过程中，就会发现以下续租困境：</p>

<ol>
<li>Proposer A获得租约，proposeId=1（此处我们为了方便，简化ProposeId的结构为提交次数），等待一段时间t后开始续租</li>
<li>Proposer B在t的过程中，不断尝试想获取续约，但始终得不到多数派的批准，这个过程中Proposer B发出提案的proposeId会飙升，比如说proposeId=10</li>
<li>Accepter们在Proposer B的不断尝试中，Prepare阶段HighestPromisedProposeId也跟着飙升，比如说HighestPromisedProposeId=10</li>
<li>Proposer A开始续租，proposeId=2，续租失败</li>
</ol>


<p>解决续租困境有几种方式：</p>

<ol>
<li>Accepter在定时器γ超时前，不接受新的PrepareRequest</li>
<li>Proposer续租时，将Request的ProposeId增加较大的值</li>
</ol>


<p>我们随机选择第二种方式，那么在时间t（t&lt;租约时长）的过程中，Proposer B能发出的Prepare Request数量，即B的ProposeId增长量Δ一定满足：Δ &lt; ceil(租约时长/定时器α时长)。即，续租时，Proposer A的proposeId += ceil(租约时长/定时器α时长)即可。</p>

<p>额外一提，Keyspace中续租的时间（在获得租约后1s就开始续租）远小于Prepare/Propose阶段的超时时间，不会触发这个困境</p>

<hr />

<h4>Proposer对HighestPromisedProposeId的学习</h4>

<p>解决了续租困境后，我们再设定一种困境：</p>

<ol>
<li>Proposer A 持有租约，并一直续租，导致ProposeId变得很大，比如ProposeId = 10000</li>
<li>Accepter们的HighestPromisedProposeId也变得很大，比如HighestPromisedProposeId = 10000</li>
<li>此时Proposer A离线</li>
<li>Proposer B 闪亮登场（比如在集群中补充了一台server），欲接手，发出PrepareRequest，ProposeId = 0</li>
<li>Proposer B 想要持有租约，至少要经过近10000次重试，才能将ProposeId增大到Accepter可接受的大小</li>
</ol>


<p>这个困境的关键是在Proposer知晓的ProposeId太过落后于集群内最新的ProposeId，导致Proposer无法短时间内获得租约，而是需要长时间的重试</p>

<p>有两种解决方案可供参考：</p>

<ol>
<li>Keyspace用的是这种方法：认为一个节点由Proposer和Accepter构成，即同一个节点Proposer和Accepter可以共享HighestPromisedProposeId。<br/>这样在上述情况下，只要集群里有任何一个Request被发给Accepter B，那么Proposer B 也可以学习到集群最新的ProposeId</li>
<li>另一种方案是加入PrepareReject消息，在消息中Accpeter加入HighestPromisedProposeId供Promised学习，即<br/>
<strong>{5}</strong> = 向Proposer A反馈Prepare Reject，其中带有HighestPromisedProposeId<br/>
<strong>{6}</strong> = 若Proposer A收到Accepter B的Prepare Reject，则学习其中的HighestPromisedProposeId</li>
</ol>


<p>第二种方案还需考虑网络延迟的情况，即Prepare Reject被长期延迟的情况。不过这种延迟并不会带来影响，因为</p>

<ol>
<li>Proposer较晚学习到HighestPromisedProposeId，不会发生错误，只会延迟产生正确的投票结果</li>
<li>Prepare Reject的处理过程中，Proposer也会判断此消息是否是当前Request产生的Response。若Prepare Reject延迟较长，Proposer会发起新一轮的Prepare Request，收到旧的Prepare Reject则会抛弃此消息。</li>
</ol>


<hr />

<h4>放弃租约</h4>

<p>实际应用中，会碰到这种情况：持有租约的服务器同时肩负着其他资源的“敏感角色”，比如数据库集群中的主服务器。此时若此server挂掉，则需要等待租约过期，重新投票产生新的租约持有者，然后再由新的租约持有者裁决出新的数据库主服务器，并进行数据保护迁移。这个过程由于集群租约持有者和数据库主服务器这两种角色同时消失，会带来较大的影响。</p>

<p>为解决以上情况，就希望若两种角色重叠在一台server上，此时server能在<strong>运行稳定时</strong>放弃租约，做法有两种：</p>

<ol>
<li><p>如参考[1]中提到：“请求者可以发送一个特定释放消息给接受者，消息中包含了它要释放租给的投票编号。在发送释放消息之前，请求者把内部状态从“我持有租约”切换到“我没有持有租约”。”。<br/><br/>
考虑“释放消息”被长期延迟的情况，最坏的情况是没有Accepter及时收到消息，跟正常租约超时一样，需要等到多数派Accepter的定时器γ都超时，才能选出新的master。看来不会对正确性带来较大影响，只是不能及时释放租约。</p></li>
<li><p>懒惰一点，就等到租约超时。为了不让当前Proposer再成为租约持有者，将当前Proposer“冻结” 2倍租约时长，这样既可以等到当前租约超时，又可以避免参与到下一轮投票。<br/><br/>
所谓“冻结”，即停掉一切定时器，且不发出新的request</p></li>
</ol>


<hr />

<p>至此，此篇已经描述了在实现PaxosLease中碰到的一切问题和取舍，欢迎各位反馈。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[对于PaxosLease的个人理解 1]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2013/12/19/paxos-lease/"/>
    <updated>2013-12-19T20:19:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2013/12/19/paxos-lease</id>
    <content type="html"><![CDATA[<p>Paxos是分布式解决数据一致性的算法，而PaxosLease是Paxos中的一个子集，用于在集群中选择出一个节点作为master</p>

<p>最近因为项目需要，实现了一下PaxosLease，代码放在<a href="https://github.com/ikarishinjieva/PaxosLease-go">Github</a>上</p>

<p>计划用两篇blog，分别记录下自己对PaxosLease的理解，以及对PaxosLease应用时的一些变化。<br/>这篇是我对PaxosLease的个人理解，如有任何bug/改进的建议，欢迎comment</p>

<hr />

<p>首先，定义一下问题场景：有N个节点组成一个集群，需要从其中选出一个master。（其中可能遇到节点间传输的信息延迟/丢失，节点离线，网络脑裂等等状况）</p>

<p>在这个定义中，先要解决如何定义“选出一个master”，有以下几种可能</p>

<ol>
<li>仅有master节点知道自己是master，其他节点只知道自己不是master，而不知道谁是master</li>
<li>所有在线节点都知道谁是master，离线节点上线后要等待下次选举</li>
<li>所有节点都知道谁是master，离线节点上线后要立刻学习谁是master</li>
</ol>


<p>PaxosLease选择的是第一种方式（在此只讨论没有Learner的情况，有Learner的情况可以实现另外两种情况），这种方式满足现在的项目需要</p>

<p>这一个部分的结论：在以上的定义下，PaxosLease需要满足一个<em>不定式</em>：在同一时间，集群内至多有一个节点认为自己是master</p>

<hr />

<p>要在多个节点达成一致，最通常的想法是二段提交（2-phase commit，2PC），经典2PC步骤是：</p>

<ol>
<li>某节点A向其他所有节点发起PrepareRequest（准备请求）</li>
<li>某节点B收到节点A的PrepareRequest，经过状态检查，将自己的状态置为PrepareReady（表示可以接受A的PrepareRequest）<br/>并向A发送PrepareResponse（准备请求的回复）</li>
<li>A收到其他节点发来的PrepareResponse，当满足<em>某个条件</em>时，A认为集群整体同意了他得PrepareRequest。<br/>于是A向其他所有节点发出CommitRequest（提交请求）</li>
<li>节点B收到A的CommitRequest，且检查到<em>当前状态是为A准备的状态</em>，则向A发送CommitResponse（提交回复）</li>
<li>A收到其他节点发来的CommitResponse，当满足<em>某个条件</em>时，A认为集群已经完成了提交</li>
</ol>


<p><img src="http://ikarishinjieva.github.com/blog/images/2013-12-19-paxos-lease-1.png"></p>

<p>但经典的2PC没有以下解决的问题：</p>

<ol>
<li>如何处理网络脑裂</li>
<li>如何解决master突然离线，比如网络故障</li>
<li>如何面对选举过程中通信可能发生的延迟和中断</li>
<li>是否会发生动态死锁</li>
</ol>


<hr />

<p>这一部分先解决网络脑裂的问题。比如有5个节点的集群，分割为[1,2]和[3,4,5]，那么在[1,2]子集群中不能选举出master，而在[3,4,5]子集群中必须要选举出master。若脑裂前master落在[1,2]，那么租约到期后，[1,2]不能选举出master</p>

<p>解决方案是：指定2PC步骤中的<em>某个条件</em>为“收到集群中超过集群节点数一半的节点（多数派）的正反馈”。那么[3,4,5]子集群可能选出master，而[1,2]由于只有2个节点，小于ceil(5/2) = 3，没法选出master</p>

<p>在此，我们称一个集群中，超过集群节点数一半的节点集合为多数派</p>

<hr />

<p>这一部分将解决master突然离线的问题。根据<em>不变式</em>，除了master本身，没有节点知道谁是master。在这种情况下，如果不做点什么，集群就不会再有master了</p>

<p>解决方案是使用租约，即谁持有租约谁是master。</p>

<br/>由于是多数派选举master时，选举出master时，多数派的每个节点都会开始一个定时器，时长和租约时长相同


<br/>于是在租约过期前，多数派的定时器都不会超时，多数派不会参与投票，即集群选不出新的master


<br/>那么在租约过期后，多数派的定时器都超时，可以投票，集群就可以重新选举出master


<br/>整个过程与离线的master没有任何交互，也就可以在master离线时选举出新的master


<p>且整个过程中，租约到期前（多数派定时器超时前），集群不会有两个master同时存在，即满足<em>不定式</em></p>

<p>以上<em>等到租约过期</em>的做法有一个前提，即所有节点都知道统一的租约时长 （此处是时长，而不是过期时间。PaxosLease并不要求各个节点时钟同步，因此必须使用时长）。这是时长往往是静态配置，而不是动态协商的</p>

<hr />

<p>这一部分将解决选举过程中通信可能发生延迟。</p>

<p>发生延迟意味着A-B已经进入了下一轮投票，C可能才完成上一轮投票，C的反馈可能影响到这一轮投票结果。</p>

<p>此处PaxosLease引入了投票ID（PaxosLease称ProposeId，后面会统一名称的）的概念，投票ID对于某一节点A，在全局是单调递增的。常用的投票ID结构为&lt;投票轮数 | 重启计数 | 节点ID>（“|”为字符串拼接），这个ID可以被持久化存储，即新一轮投票或节点重启时投票ID都会单调递增。</p>

<p>有了投票ID，那么节点可以只响应本轮的反馈，而不受其他轮的干扰。</p>

<hr />

<p>这一部分将解决选举过程中通信可能发生中断。</p>

<p>发生中断意味着2PC某阶段会一直等待多数派的反馈，但反馈都丢失了，于是选举可能被无限期拖延下去。很容易得出解决方案：设置超时时间。即在2PC每一个阶段都设置超时时间，若超时，则回退重新开始新一轮的2PC</p>

<hr />

<p>这一部分将讨论如何解决动态死锁</p>

<p>首先说明何为动态死锁，比如有4个节点的集群[1,2,3,4]，1和4同时请求自己为master，1的request发给2，而4的request发给3，没有任何一方获得多数派，于是进入新的一轮，以上状况重复出现，陷入死循环，没法选出master</p>

<p>观察这个问题的症结在于，2收到1的prepare request后，进入PrepareReady状态，将不再接受4发来的请求。这样[1,2]和[3,4]不断对撞，陷入死锁。</p>

<p>解决方案是PaxosLease引入了“不稳定”的PrepareReady，即2进入为1准备的PrepareReady状态后，如果收到4的PrepareRequest，且这个投票ID大于来自1的PrepareRequest的投票ID，则2转而进入为4准备的PrepareReady</p>

<p>可以看到投票ID代表了优先级，也就能理解之前要求<strong>某节点</strong>的投票ID单调递增的理由了</p>

<p>需要说明的是，上述做法只是大大降低动态死锁的概率，但仍然可能存在小概率的动态死锁，即两个节点1和4不断增大投票ID且在2和3进入Commit之前不断抢占2和3，形成竞争，可以引入随机的等待来规避这个小概率事件</p>

<hr />

<p>在此，将上面描述的名词对应到PaxosLease算法的术语上</p>

<ul>
<li>租约 = lease（租约）</li>
<li>投票 = propose (提案)</li>
<li>发出request的节点 = proposer</li>
<li>接受request，发出response的节点 = accepter</li>
<li>CommitRequest = ProposeRequest</li>
<li>CommitResponse = ProposeReponse</li>
<li>投票ID = ProposeID</li>
</ul>


<p>之后将使用术语</p>

<hr />

<p>以上，是出于个人理解，来理解PaxosLease的几个重要元素：</p>

<ol>
<li>lease</li>
<li>propose</li>
<li>ProposeId</li>
<li>两阶段的超时设置</li>
<li>多数派形成决议</li>
</ol>


<p>一些实现上的问题会在下一篇blog讨论</p>

<hr />

<p>再次讨论<em>不变式</em></p>

<p>在某一时刻，集群中最多存在一个Proposer，知道自己获得了租约。</p>

<p>此时，多数Accepter知道在<em>某一个时刻</em>前某个提案（AcceptedProposeId）是生效的。其他Proposer了解到多数Accepter都有AcceptedProposeId，则其不能获得租约。</p>

<p>这里说明一下上句中的<em>某一时刻</em>。借用参考[1]中的图</p>

<p><img src="http://ikarishinjieva.github.com/blog/images/2013-12-19-paxos-lease-2.png"></p>

<p>可以看到Proposer和Accepter间有时间差，即<em>某一个时刻</em>指的是当前Accepter定时器超时的时刻（可能晚于Proposer上租约到期的时刻），但这并没有影响<em>不变式</em>成立。即在满足当前不变式时，<strong>不要求各个节点时钟同步</strong></p>

<hr />

<p>以上是我个人的理解，如有不妥，烦请看官comment</p>

<p>建议此时参看文末的参考文献和Keyspace源码。之后请期待下一篇：实现PaxosLease中的一些问题和解决</p>

<p>顺便吐个槽，我没有数学天赋和算法天赋，也实在没兴趣下苦工，实在不够进取。罪过罪过。</p>

<hr />

<h2>参考文献</h2>

<p>[1]<a href="http://dsdoc.net/paxoslease/index.html">【译】PaxosLease：实现租约的无盘Paxos算法</a></p>

<p>[2] <a href="https://github.com/scalien/keyspace/tree/master/src/Framework/PaxosLease">Keyspace源码</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[关于DEV测试的一些经验总结]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2013/12/09/test-framework-exp/"/>
    <updated>2013-12-09T20:05:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2013/12/09/test-framework-exp</id>
    <content type="html"><![CDATA[<p>已经是第三遍重写项目主代码了，这几天用主代码和测试框架互相补充。总结下经验值，以期升级</p>

<hr />

<p>关于测试框架，重写了几遍仍然保留下来的功重要能是：</p>

<ol>
<li><p>插桩代码，后面的功能也都依赖插桩。不在主代码中插桩，测试基本靠拜神；</p></li>
<li><p>条件池，根据条件池，代码才能沿着需要的分支进行；</p></li>
<li><p>签到点（checkpoint），代码要能根据测试要求停得下来，等待状态，之后跑得起来；</p></li>
<li><p>外缘测试。比起直接测试变量，还是分析log比较容易维护</p></li>
</ol>


<p>测试的难点是：</p>

<ol>
<li><p>资源回收。要连续跑测试，资源回收是说说容易的事。tcp server关了，listener停了，关闭的那些connection会不会瞬时占用临时端口；如果某一个connection正在申请二步锁，测试停止时远端锁失败，近端锁如果不释放会不会影响之后的测试；如果系统会自动重启tcp server，tcp server是在测试关闭操作之前停还是之后停还是停两次。想想头就大了。</p></li>
<li><p>想停都停不下来，万一断言失败，测试要能停下来。整个flow上都要处理停止中断，用“硬”中断很难掌握资源回收的状况；用“模拟”中断，所有等待/超时/重试的地方都要处理，逐级退栈。比起不测试的代码，主代码花在错误处理的代码量要大很多，但是值得。</p></li>
<li><p>测试界限把握不易。测粗了没作用，测细了耗时间而且波动大。插桩的深度，模拟中断的层级，这些都要拿好轻重。否则代码已腐败。</p></li>
</ol>


<p>每次跑测试，比起旁边坐个QA的测试，更步步惊心。QA一天才跑十几个case，自动的话2-3分钟就跑十几个简化的case，出错的概率要大很多。</p>

<p>最后反思一下，如果靠人肉测，&#8230;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[对Memory Reordering Caught in the Act的学习 续 - 关于go的部分]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2013/11/11/study-memory-reorder-cont/"/>
    <updated>2013-11-11T20:44:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2013/11/11/study-memory-reorder-cont</id>
    <content type="html"><![CDATA[<p>这篇主要解决<a href="http://ikarishinjieva.github.io/blog/blog/2013/11/07/study-memory-reorder/">上一篇</a>遗留下来的问题，问题的简要描述请参看<a href="http://stackoverflow.com/questions/19901615/why-go-doesnt-show-memory-reordering">我发在SO上的帖子</a></p>

<p>主要的问题是用c++可以重现memory reordering，但go的程序没有重现</p>

<p>主要的结论是写go的时候我忘记设置GOMAXPROC，在目前这个go版本(1.2 rc2)下，不设置GOMAXPROC goroutine不会并发的，自然也没法设置memory reordering</p>

<p>此篇主要内容到此结束，以下是这两天的一些探索过程和技巧，觉得还是挺有意思的</p>

<hr />

<h4>go tool生成的汇编码和真实的汇编码是有很大差距的</h4>

<p>这个结论并不奇怪，但是差异的程度还是会影响诸如lock-free的代码的使用前提</p>

<p>对以下代码做对比</p>

<pre><code>x = 1
r1 = y
</code></pre>

<p>使用<code>go tool 6g -S xxx.go</code>反编译后的代码</p>

<pre><code>0246 (a.go:25) MOVQ    $1,x+0(SB)   //X=1
0247 (a.go:26) MOVQ    y+0(SB),BX
0248 (a.go:26) MOVQ    BX,r1+0(SB)  //r1=Y
</code></pre>

<p>而真实运行在cpu上的代码（<code>ndisasm -b 32 xxx</code>)为</p>

<pre><code>000013EB  C70425787F170001  mov dword [0x177f78],0x1     //X=1
         -000000
000013F6  48                dec eax
000013F7  8B1C25807F1700    mov ebx,[0x177f80]
000013FE  48                dec eax
000013FF  891C25687F1700    mov [0x177f68],ebx          //r1=Y
00001406  48                dec eax
</code></pre>

<p>可以看到在访问共享内存的前后多出了<code>dec eax</code>作为margin，这个原因不明，也没有找到相应的资料</p>

<p>但总的来说<code>ndisasm</code>产生的汇编代码更方便于对go行为的理解</p>

<hr />

<h4>一个小技巧快速定位汇编码</h4>

<p>我对intel指令集和go的编译器知之甚少，读起汇编码来颇为费劲。</p>

<p>快速定位源码对应的汇编码的位置，比较方便的就是修改一个数值，比如x=1改为x=2，前后生成的汇编码diff一下，就可以大概确定位置了</p>

<hr />

<h4>替换c++生成文件的指令</h4>

<p>在探索过程中，我想做个对比实验来证明是否上面所说的<code>dec eax</code>引起了c++和go在memory reordering上的差异，于是就想将<code>dec eax</code>也加到c++的生成文件中，这样就可以对比效果</p>

<p>碰到的问题是如果我直接将<code>asm volatile("dec %eax")</code>直接加到c++源码中，生成的汇编代码不是<code>48</code>，而是<code>FExxxx</code>。翻看<a href="http://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-vol-2a-manual.pdf">Intel® 64 and IA-32 Architectures
Software Developer’s Manual</a>，可知<code>dec</code>有多种形式</p>

<p>但是我不想研究为什么编译器会选择<code>FExxxx</code>而不是<code>48</code>，而是想尽快将c++生成的汇编代码形式做成和go一样。于是就有了下面的步骤：</p>

<ol>
<li><code>48</code>有两个字节，我也选取两个字节的op写在c++源码中，比如<code>asm volatile("cli")</code></li>
<li>c++编译生成，然后用16进制编辑器将<code>cli</code>生成的两个字节换成<code>48</code>即可</li>
</ol>


<p>之所以选择替换是因为怕有checksum或者内存位置的偏移，我也不知道有还是没有&#8230;</p>

<p>对比实验证明<code>dec eax</code>不是引起差异的原因</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[对Memory Reordering Caught in the Act的学习]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2013/11/07/study-memory-reorder/"/>
    <updated>2013-11-07T21:40:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2013/11/07/study-memory-reorder</id>
    <content type="html"><![CDATA[<p>最近迷上了preshing.com，真的是非常专业的blog，每篇深浅合适而且可以相互印证，达到出书的质量了</p>

<p>学习了<a href="http://preshing.com/20120515/memory-reordering-caught-in-the-act/">Memory Reordering Caught in the Act</a>，内容很简单，主要是说“即使汇编码是顺序的，CPU执行时会对Load-Save进行乱序执行，导致无锁的两线程出现意料之外的结果”</p>

<p>简述一下：</p>

<ul>
<li>首先我们有两个线程，Ta和Tb，且有四个公共变量，a,b,r1,r2</li>
<li>Ta的代码是 a=1, r1=b</li>
<li>Tb的代码是 b=1, r2=a</li>
<li>保证编译器不做乱序优化</li>
<li>由于两个线程的读都在写之后，那么理论上，r1和r2中至少有一个应为1，或者都为1</li>
<li>但实际并非如此</li>
</ul>


<p>原因是CPU会做乱序执行，因为Ta/Tb的代码乱序后，比如r1=b, a=1，从单线程的角度来看对结果没有影响。而对于多线程，就会出现r1=r2=0的状况</p>

<p>解决方案是在两句之间插入Load-Save fence，参看<a href="http://preshing.com/20120710/memory-barriers-are-like-source-control-operations/">这里</a></p>

<p>我自己用go想重现这个场景，代码参看最后。但是奇怪的是go的编译码跟文章描述的差不多</p>

<pre><code>[thread 1]
...
MOVQ    $1,a+0(SB)
MOVQ    b+0(SB),BX
MOVQ    BX,r1+0(SB)

[thread 2]
MOVQ    $1,b+0(SB)
MOVQ    a+0(SB),BX
MOVQ    BX,r2+0(SB)
</code></pre>

<p>但是在MBP (Intel Core i7)上跑并没有出现CPU乱序的现象，希望有同学能帮我提供线索，谢谢</p>

<p>(2013.11.11 更新：关于以上现象的原因参看<a href="http://ikarishinjieva.github.io/blog/blog/2013/11/11/study-memory-reorder-cont/">续 - 关于go的部分</a>)</p>

<p>go 代码：</p>

<pre><code>package main

import (
    "fmt"
    "math/rand"
)

var x, y, r1, r2 int
var detected = 0

func randWait() {
    for rand.Intn(8) != 0 {
    }
}

func main() {
    beginSig1 := make(chan bool, 1)
    beginSig2 := make(chan bool, 1)
    endSig1 := make(chan bool, 1)
    endSig2 := make(chan bool, 1)
    go func() {
        for {
            &lt;-beginSig1
            randWait()
            x = 1
            r1 = y
            endSig1 &lt;- true
        }
    }()
    go func() {
        for {
            &lt;-beginSig2
            randWait()
            y = 1
            r2 = x
            endSig2 &lt;- true
        }
    }()
    for i := 1; ; i = i + 1 {
        x = 0
        y = 0
        beginSig1 &lt;- true
        beginSig2 &lt;- true
        &lt;-endSig1
        &lt;-endSig2
        if r1 == 0 &amp;&amp; r2 == 0 {
            detected = detected + 1
            fmt.Println(detected, "reorders detected after ", i, "iterations")
        }
    }
}
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[对heartbeat φ累积失败检测算法的学习]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2013/11/05/accrual-failure-detector/"/>
    <updated>2013-11-05T21:50:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2013/11/05/accrual-failure-detector</id>
    <content type="html"><![CDATA[<p>偶尔读到了这篇&#8221;<a href="http://blog.csdn.net/chen77716/article/details/6541968">φ累积失败检测算法</a>&#8220;，写的非常不错。藉此了解了这个用于heartbeat检测的算法，在此记录一下我自己理解的简单版本</p>

<p>heartbeat时我们使用固定的时间限制t0，当heartbeat的返回时长超过t0时，就认为heartbeat失败。这个方法的弊端是：固定的t0是在事先测定的，不会随网络状况的变化而智能变化。φ累积失败检测算法就是要解决这个问题</p>

<p>失败检验算法的基本思想就是：成功判定“heartbeat失败”的概率符合<a href="http://zh.wikipedia.org/wiki/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83">正态分布曲线</a>，x轴是本次心跳距上次心跳的差距时间，y轴是差距为x的心跳的概率。</p>

<br/>也就是说，假设我们已经有一条正态分布的曲线，当前时间是Tnow，上次心跳成功的时间是Tlast，那么从(Tlast-Tnow) ~ +∞这个区间内的积分（设为w，w<1）就代表某心跳间隔从Tlast维持到大于Tnow的时间的概率，即在Tnow时判定“heartbeat失败”的<b>失败率</b>，就是说如果我们在Tnow这个时间点判定“heartbeat失败”，那么有w的概率我们做出了错误的判定（heartbeat本该是成功的，也许只是被延迟了= =）


<p>臆测这个算法的基本步骤是：</p>

<ol>
<li>我们假设判定失败率的阈值是&lt;=10%，也就是允许我们判定“heartbeat失败”时最大失败率为10%。</li>
<li>取样本空间，比如前N次心跳的差距时间（心跳接收时间-上次心跳的接收时间）。计算这个样本空间的均值和方差，就可以计算出正态分布曲线</li>
<li>在某时间Tnow，计算(Tlast-Tnow) ~ +∞这个区间内的积分（设为w），即为判定“heartbeat失败”的<b>失败率</b>，若大于阈值10%，则可以判定“heartbeat”失败</li>
<li>重复取样，继续算法</li>
</ol>


<p>到此基本结束，以下是对原文&#8221;<a href="http://blog.csdn.net/chen77716/article/details/6541968">φ累积失败检测算法</a>&#8220;的一些个人补充</p>

<ul>
<li>原文有φ这个变量，主要是因为计算出来的判定失败率可能经常是非常小的小数，所以φ取其负对数，方便比较</li>
<li>在此不再重复引用原文的公式</li>
</ul>


<p>最后，可参考论文<a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;ved=0CDEQFjAA&amp;url=http%3A%2F%2Fddg.jaist.ac.jp%2Fpub%2FHDY%2B04.pdf&amp;ei=L_94Uo3OGomciQLCx4GQBg&amp;usg=AFQjCNGYrM_1R5LmY4wrDlKnykatr3VBRA&amp;sig2=G8d5gBsR8MpIwgfU9Xbt7A&amp;bvm=bv.55980276,d.cGE">
The φ Accrual Failure Detector</a>：</p>

<ul>
<li>这篇论文非常详细（啰嗦）地描述了要解决的问题场景</li>
<li>这篇论文给出了一般性的累积失败检测法要满足的特性</li>
<li>这篇论文给出了用正态分布曲线来计算的步骤</li>
<li>这篇论文给出了算法正确性的比较结果</li>
</ul>


<p>最后的最后，推荐<a href="http://blog.csdn.net/chen77716">这个大牛陈国庆的blog</a>，其中文章写的质量高，里面也有对Paxos算法的介绍，配合paxos的wiki，解析的很到位</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[对Mysql bug #70307 的学习]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2013/10/25/study-mysql-bug-70307/"/>
    <updated>2013-10-25T22:00:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2013/10/25/study-mysql-bug-70307</id>
    <content type="html"><![CDATA[<p>之前描述<a href="http://ikarishinjieva.github.io/blog/blog/2013/10/11/hole-in-mysql-56-replication-dead-lock/">Mysql 5.6.15 Replication中碰到的死锁</a>的情况，这次尝试debug下原因。</p>

<h2>debug的过程</h2>

<p>用参数&#8211;gdb启动mysql，按照<a href="http://bugs.mysql.com/file.php?id=20542">步骤</a>重现bug（让slave &#8220;show slave status&#8221;时卡住）。然后用gdb attach到slave mysql实例上。</p>

<pre><code>(gdb) thread apply all bt
</code></pre>

<p>输出所有线程的backtrace，找到show slave status卡住的线程和位置</p>

<pre><code>Thread 2 (Thread 0x7f583c166700 (LWP 2440)):
#0  0x00007f583f484054 in __lll_lock_wait () from /lib64/libpthread.so.0
#1  0x00007f583f47f3be in _L_lock_995 () from /lib64/libpthread.so.0
#2  0x00007f583f47f326 in pthread_mutex_lock () from /lib64/libpthread.so.0
#3  0x0000000000aa3cde in safe_mutex_lock (mp=0x3516ae8, try_lock=0 '\000', file=0xfb8e58 "/home/vagrant/mysql-5.6.12/sql/rpl_slave.cc", line=2611) at /home/vagrant/mysql-5.6.12/mysys/thr_mutex.c:152
#4  0x0000000000a4b993 in inline_mysql_mutex_lock (that=0x3516ae8, src_file=0xfb8e58 "/home/vagrant/mysql-5.6.12/sql/rpl_slave.cc", src_line=2611) at /home/vagrant/mysql-5.6.12/include/mysql/psi/mysql_thread.h:686
#5  0x0000000000a53cb3 in show_slave_status (thd=0x352e3d0, mi=0x34b4f20) at /home/vagrant/mysql-5.6.12/sql/rpl_slave.cc:2611
#6  0x00000000007d45f4 in mysql_execute_command (thd=0x352e3d0) at /home/vagrant/mysql-5.6.12/sql/sql_parse.cc:2766
#7  0x00000000007ddc46 in mysql_parse (thd=0x352e3d0, rawbuf=0x7f57ec005010 "show slave status", length=17, parser_state=0x7f583c165660) at /home/vagrant/mysql-5.6.12/sql/sql_parse.cc:6187
#8  0x00000000007d1019 in dispatch_command (command=COM_QUERY, thd=0x352e3d0, packet=0x3534e51 "", packet_length=17) at /home/vagrant/mysql-5.6.12/sql/sql_parse.cc:1334
#9  0x00000000007d017b in do_command (thd=0x352e3d0) at /home/vagrant/mysql-5.6.12/sql/sql_parse.cc:1036
#10 0x0000000000797a08 in do_handle_one_connection (thd_arg=0x352e3d0) at /home/vagrant/mysql-5.6.12/sql/sql_connect.cc:977
#11 0x00000000007974e4 in handle_one_connection (arg=0x352e3d0) at /home/vagrant/mysql-5.6.12/sql/sql_connect.cc:893
#12 0x0000000000aea87a in pfs_spawn_thread (arg=0x351b510) at /home/vagrant/mysql-5.6.12/storage/perfschema/pfs.cc:1855
#13 0x00007f583f47d851 in start_thread () from /lib64/libpthread.so.0
#14 0x00007f583e3e890d in clone () from /lib64/libc.so.6
</code></pre>

<p>可以看到show slave status卡在</p>

<pre><code>#5  0x0000000000a53cb3 in show_slave_status (thd=0x352e3d0, mi=0x34b4f20) at /home/vagrant/mysql-5.6.12/sql/rpl_slave.cc:2611
</code></pre>

<p>查找源码可以看到show slave status卡在获取锁mi->rli->data_lock上<br/>(科普下缩写: mi=master info, rli=relay log info</p>

<p>在gdb中运行命令</p>

<pre><code>(gdb) thread 2
(gdb) f 5
(gdb) print mi-&gt;rli-&gt;data_lock
</code></pre>

<p>切换到thread 2堆栈第5层的上下文，打印出mi->rli->data_lock变量，输出如下</p>

<pre><code>$1 = {m_mutex = {global = {__data = {__lock = 0, __count = 0, __owner = 0, __nusers = 0, __kind = 2, __spins = 0,
    __list = {__prev = 0x0, __next = 0x0}},
  __size = '\000' &lt;repeats 16 times&gt;, "\002", '\000' &lt;repeats 22 times&gt;, __align = 0}, mutex = {__data = {
    __lock = 2, __count = 0, __owner = 2435, __nusers = 1, __kind = 3, __spins = 0, __list = {__prev = 0x0,
      __next = 0x0}},
  __size = "\002\000\000\000\000\000\000\000\203\t\000\000\001\000\000\000\003", '\000' &lt;repeats 22 times&gt;,
  __align = 2}, file = 0xfa4520 "/home/vagrant/mysql-5.6.12/sql/log_event.cc", line = 7259, count = 1,
thread = 140016942216960}, m_psi = 0x0}
</code></pre>

<p>看到锁的owner是线程(LWP 2435)，为Thread 3</p>

<p>Thread 3的backtrace如下</p>

<pre><code>Thread 3 (Thread 0x7f583c1a7700 (LWP 2435)):
#0  0x00007f583f4817bb in pthread_cond_timedwait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0
#1  0x0000000000aa429d in safe_cond_timedwait (cond=0x7f57f4000ba8, mp=0x7f57f4000b38, abstime=0x7f583c1a60f0, file=0xedc960 "/home/vagrant/mysql-5.6.12/include/mysql/psi/mysql_thread.h", line=1199) at /home/vagrant/mysql-5.6.12/mysys/thr_mutex.c:278
#2  0x00000000007121f4 in inline_mysql_cond_timedwait (that=0x7f57f4000ba8, mutex=0x7f57f4000b38, abstime=0x7f583c1a60f0, src_file=0xedcb98 "/home/vagrant/mysql-5.6.12/sql/mdl.cc", src_line=1306) at /home/vagrant/mysql-5.6.12/include/mysql/psi/mysql_thread.h:1199
#3  0x0000000000713111 in MDL_wait::timed_wait (this=0x7f57f4000b38, owner=0x7f57f4000a50, abs_timeout=0x7f583c1a60f0, set_status_on_timeout=true, wait_state_name=0x14d0488) at /home/vagrant/mysql-5.6.12/sql/mdl.cc:1306
#4  0x0000000000714811 in MDL_context::acquire_lock (this=0x7f57f4000b38, mdl_request=0x7f583c1a6180, lock_wait_timeout=31536000) at /home/vagrant/mysql-5.6.12/sql/mdl.cc:2241
#5  0x000000000063656a in ha_commit_trans (thd=0x7f57f4000a50, all=true) at /home/vagrant/mysql-5.6.12/sql/handler.cc:1396 (COMMIT LOCK)
#6  0x00000000008a010b in trans_commit (thd=0x7f57f4000a50) at /home/vagrant/mysql-5.6.12/sql/transaction.cc:228
#7  0x0000000000a081bb in Xid_log_event::do_commit (this=0x7f57f4004730, thd=0x7f57f4000a50) at /home/vagrant/mysql-5.6.12/sql/log_event.cc:7174
#8  0x0000000000a0886e in Xid_log_event::do_apply_event (this=0x7f57f4004730, rli=0x3516650) at /home/vagrant/mysql-5.6.12/sql/log_event.cc:7310 (rli-&gt;data_lock)
#9  0x00000000009fd956 in Log_event::apply_event (this=0x7f57f4004730, rli=0x3516650) at /home/vagrant/mysql-5.6.12/sql/log_event.cc:3049
#10 0x0000000000a55e31 in apply_event_and_update_pos (ptr_ev=0x7f583c1a68a0, thd=0x7f57f4000a50, rli=0x3516650) at /home/vagrant/mysql-5.6.12/sql/rpl_slave.cc:3374
#11 0x0000000000a56e45 in exec_relay_log_event (thd=0x7f57f4000a50, rli=0x3516650) at /home/vagrant/mysql-5.6.12/sql/rpl_slave.cc:3742
#12 0x0000000000a5c334 in handle_slave_sql (arg=0x34b4f20) at /home/vagrant/mysql-5.6.12/sql/rpl_slave.cc:5552
#13 0x0000000000aea87a in pfs_spawn_thread (arg=0x350a800) at /home/vagrant/mysql-5.6.12/storage/perfschema/pfs.cc:1855
#14 0x00007f583f47d851 in start_thread () from /lib64/libpthread.so.0
#15 0x00007f583e3e890d in clone () from /lib64/libc.so.6
</code></pre>

<p>可以看到Thread 3卡在commit lock上，同时查源码看到Thread 3同时占有了rli->data_lock (log_event.cc:7259)</p>

<h2>锁的状态</h2>

<p>按照bug的描述，</p>

<ol>
<li>flush tables with read lock; 会持有commit lock</li>
<li>IO thread (Thread 3)会持有rli->data_lock，并等待commit lock</li>
<li>show slave status; 会等待rli->data_lock</li>
</ol>


<p>结果导致show slave status卡住不可用</p>

<h2>臆测一下解决方法</h2>

<p>鉴于功底不深，只能臆测一下</p>

<ol>
<li>IO thread持有锁rli->data_lock的原因是要更新relay log的状态，然后进行commit(Xid_log_event::do_apply_event (log_event.cc:7248))。在commit的时候不会更新rli的数据。</li>
<li>show slave status不会更新rli的数据，需要锁rli->data_lock的原因是要一致性数据。</li>
</ol>


<p>因此可能的解决方案是IO thread持有读写锁，进行commit时转为持有读锁。show slave status只使用读锁。</p>

<p>只是臆测下解决方法，待<a href="http://bugs.mysql.com/bug.php?id=70307">bug #70307</a>修掉时再学习。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mysql 5.6.12 master上flush logs在slave上产生两个relay-log]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2013/10/22/mysql-flush-logs-make-two-relay-log-file/"/>
    <updated>2013-10-22T21:42:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2013/10/22/mysql-flush-logs-make-two-relay-log-file</id>
    <content type="html"><![CDATA[<h2>现象</h2>

<p>一个碰巧观察到的有趣的现象：mysql 5.6.12 在master上flush logs，在slave上会观察到两个新的relay-log file</p>

<p>举例：</p>

<p>slave-relay-bin.000092</p>

<pre><code> FD event
 Rotate to mysql-bin.000056
 Rotate to slave-relay-bin.000093
</code></pre>

<p>slave-relay-bin.000093</p>

<pre><code> FD event slave
 Rotate to mysql-bin.000056
 FD event master
 bla bla…
</code></pre>

<p>可以看到000092这个relay log相当多余。这个现象并不会影响replication的正确性，只是让有强迫症的人有点狂躁</p>

<h2>探索</h2>

<p>在master上net_serv.cc:my_net_write打断点，可以观察到master的确发出了以下三个事件</p>

<ul>
<li>ROTATE_EVENT</li>
</ul>


<p>backtrace</p>

<pre><code>#0  my_net_write (net=0x1ea2858, packet=0x7fffa4002b70 "", len=48)
    at /home/vagrant/mysql-5.6.12/sql/net_serv.cc:284
#1  0x0000000000a48b05 in mysql_binlog_send (thd=0x1ea2600, log_ident=0x7fffa4004c60 "mysql-bin.000052", pos=167,
    slave_gtid_executed=0x0) at /home/vagrant/mysql-5.6.12/sql/rpl_master.cc:1336
#2  0x0000000000a46ad2 in com_binlog_dump (thd=0x1ea2600, packet=0x1ea5d21 "", packet_length=26)
    at /home/vagrant/mysql-5.6.12/sql/rpl_master.cc:746
#3  0x00000000007d1ab9 in dispatch_command (command=COM_BINLOG_DUMP, thd=0x1ea2600, packet=0x1ea5d21 "",
    packet_length=26) at /home/vagrant/mysql-5.6.12/sql/sql_parse.cc:1534
#4  0x00000000007d017b in do_command (thd=0x1ea2600) at /home/vagrant/mysql-5.6.12/sql/sql_parse.cc:1036
#5  0x0000000000797a08 in do_handle_one_connection (thd_arg=0x1ea2600)
    at /home/vagrant/mysql-5.6.12/sql/sql_connect.cc:977
#6  0x00000000007974e4 in handle_one_connection (arg=0x1ea2600)
    at /home/vagrant/mysql-5.6.12/sql/sql_connect.cc:893
#7  0x0000000000aea87a in pfs_spawn_thread (arg=0x1e7aa80)
    at /home/vagrant/mysql-5.6.12/storage/perfschema/pfs.cc:1855
#8  0x00007ffff7bc7851 in start_thread () from /lib64/libpthread.so.0
#9  0x00007ffff6b3290d in clone () from /lib64/libc.so.6
</code></pre>

<ul>
<li>第二个ROTATE_EVENT</li>
</ul>


<p>backtrace</p>

<pre><code>#0  my_net_write (net=0x1ea2858, packet=0x7fffa4002ab0 "", len=48)
    at /home/vagrant/mysql-5.6.12/sql/net_serv.cc:284
#1  0x0000000000a45f04 in fake_rotate_event (net=0x1ea2858, packet=0x1ea2be8,
    log_file_name=0x7fffc94ff270 "./mysql-bin.000056", position=4, errmsg=0x7fffc94ffdb0,
    checksum_alg_arg=1 '\001') at /home/vagrant/mysql-5.6.12/sql/rpl_master.cc:395
#2  0x0000000000a4a33d in mysql_binlog_send (thd=0x1ea2600, log_ident=0x7fffa4004c60 "mysql-bin.000052", pos=167,
    slave_gtid_executed=0x0) at /home/vagrant/mysql-5.6.12/sql/rpl_master.cc:1728
#3  0x0000000000a46ad2 in com_binlog_dump (thd=0x1ea2600, packet=0x1ea5d21 "", packet_length=26)
    at /home/vagrant/mysql-5.6.12/sql/rpl_master.cc:746
#4  0x00000000007d1ab9 in dispatch_command (command=COM_BINLOG_DUMP, thd=0x1ea2600, packet=0x1ea5d21 "",
    packet_length=26) at /home/vagrant/mysql-5.6.12/sql/sql_parse.cc:1534
#5  0x00000000007d017b in do_command (thd=0x1ea2600) at /home/vagrant/mysql-5.6.12/sql/sql_parse.cc:1036
#6  0x0000000000797a08 in do_handle_one_connection (thd_arg=0x1ea2600)
    at /home/vagrant/mysql-5.6.12/sql/sql_connect.cc:977
#7  0x00000000007974e4 in handle_one_connection (arg=0x1ea2600)
    at /home/vagrant/mysql-5.6.12/sql/sql_connect.cc:893
#8  0x0000000000aea87a in pfs_spawn_thread (arg=0x1e7aa80)
    at /home/vagrant/mysql-5.6.12/storage/perfschema/pfs.cc:1855
#9  0x00007ffff7bc7851 in start_thread () from /lib64/libpthread.so.0
#10 0x00007ffff6b3290d in clone () from /lib64/libc.so.6
</code></pre>

<ul>
<li>FORMAT_DESCRIPTION_EVENT</li>
</ul>


<p>可以看到第一个ROTATE_EVENT是由flush logs发出的，第二个ROTATE_EVENT是fake_rotate_event</p>

<h2>关于fake_rotate_event</h2>

<p>以前也<a href="http://ikarishinjieva.github.io/blog/blog/2013/10/16/mysql-mysql_binlog_send-src/">吐槽</a>过fake_rotate_event</p>

<p>master在binlog切换时（不一定是手工flush，也可能是重启，或者容量达到限制）一定要多发一个rotate event，原因如源码rpl_master.cc:mysql_binlog_send中的注释</p>

<pre><code>  /*
    Call fake_rotate_event() in case the previous log (the one which
    we have just finished reading) did not contain a Rotate event.
    There are at least two cases when this can happen:

    - The previous binary log was the last one before the master was
      shutdown and restarted.

    - The previous binary log was GTID-free (did not contain a
      Previous_gtids_log_event) and the slave is connecting using
      the GTID protocol.

    This way we tell the slave about the new log's name and
    position.  If the binlog is 5.0 or later, the next event we
    are going to read and send is Format_description_log_event.
  */
  if ((file=open_binlog_file(&amp;log, log_file_name, &amp;errmsg)) &lt; 0 ||
      fake_rotate_event(net, packet, log_file_name, BIN_LOG_HEADER_SIZE,
                        &amp;errmsg, current_checksum_alg))
</code></pre>

<p>主要是解决之前没有rotate event发送的场景</p>

<p>虽然非常想吐槽，但是我也想不出更好的办法</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mysql rpl_slave.cc:handle_slave_io 源码的一些个人分析]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2013/10/20/mysql-handle_slave_io-src/"/>
    <updated>2013-10-20T20:17:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2013/10/20/mysql-handle_slave_io-src</id>
    <content type="html"><![CDATA[<p>读了rpl_slave.cc:handle_slave_io的源码（Mysql 5.6.11），总结一下</p>

<h2>函数概述</h2>

<p>handle_slave_io是slave io_thread的主函数，函数逻辑入口为rpl_slave.cc:start_slave_threads</p>

<h2>主体结构</h2>

<figure class='code'><figcaption><span>源码的主体结构  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">handle_slave_io</span><span class="o">(</span><span class="n">master_info</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>     <span class="mi">3955</span> <span class="n">bla</span> <span class="n">bla</span><span class="err">…</span>
</span><span class='line'>     <span class="mi">4016</span> <span class="n">fire</span> <span class="n">HOOK</span> <span class="n">binlog_relay_io</span><span class="o">.</span><span class="na">thread_start</span>
</span><span class='line'>     <span class="mi">4032</span> <span class="err">与</span><span class="n">master</span><span class="err">建立连接</span>
</span><span class='line'>    <span class="o">(</span><span class="mi">4047</span> <span class="err">设置</span><span class="n">max_packet_size</span><span class="o">)</span>
</span><span class='line'>     <span class="mi">4073</span> <span class="n">get_master_version_and_clock</span><span class="o">,</span>
</span><span class='line'>          <span class="err">在</span><span class="n">master</span><span class="err">上：</span>
</span><span class='line'>          <span class="err">通过</span><span class="n">SELECT</span> <span class="n">UNIX_TIMESTAMP</span><span class="o">()</span><span class="err">获取</span><span class="n">server</span> <span class="n">timestamp</span>
</span><span class='line'>          <span class="err">通过</span><span class="n">SHOW</span> <span class="n">VARIABLES</span> <span class="n">LIKE</span> <span class="err">&#39;</span><span class="n">SERVER_ID</span><span class="err">&#39;获取</span><span class="n">server</span> <span class="n">id</span>
</span><span class='line'>          <span class="n">SET</span> <span class="nd">@master_heartbeat_period</span><span class="o">=</span> <span class="o">?</span>
</span><span class='line'>          <span class="n">SET</span> <span class="nd">@master_binlog_checksum</span><span class="o">=</span> <span class="err">@</span><span class="nd">@global.binlog_checksum</span>
</span><span class='line'>          <span class="n">SELECT</span> <span class="nd">@master_binlog_checksum</span><span class="err">获取</span><span class="n">master</span> <span class="n">binlog</span> <span class="n">checksum</span>
</span><span class='line'>          <span class="n">SELECT</span> <span class="err">@</span><span class="nd">@GLOBAL.GTID_MODE</span>
</span><span class='line'>     <span class="mi">4075</span> <span class="n">get_master_uuid</span>
</span><span class='line'>          <span class="err">在</span><span class="n">master</span><span class="err">上“</span><span class="n">SHOW</span> <span class="n">VARIABLES</span> <span class="n">LIKE</span> <span class="err">&#39;</span><span class="n">SERVER_UUID</span><span class="err">&#39;”</span>
</span><span class='line'>     <span class="mi">4077</span> <span class="n">io_thread_init_commands</span>
</span><span class='line'>          <span class="err">在</span><span class="n">master</span><span class="err">上“</span><span class="n">SET</span> <span class="nd">@slave_uuid</span><span class="o">=</span> <span class="err">&#39;</span><span class="o">%</span><span class="n">s</span><span class="err">&#39;”</span>
</span><span class='line'>     <span class="mi">4106</span> <span class="n">register_slave_on_master</span>
</span><span class='line'>          <span class="err">向</span><span class="n">master</span><span class="err">发送</span><span class="n">COM_REGISTER_SLAVE</span>
</span><span class='line'>     <span class="mi">4133</span> <span class="k">while</span> <span class="o">(!</span><span class="n">io_slave_killed</span><span class="o">(</span><span class="n">thd</span><span class="o">,</span><span class="n">mi</span><span class="o">))</span>
</span><span class='line'>     <span class="mi">4134</span> <span class="o">{</span>
</span><span class='line'>     <span class="mi">4136</span>      <span class="n">request_dump</span>
</span><span class='line'>               <span class="err">向</span><span class="n">master</span><span class="err">发送</span><span class="n">COM_BINLOG_DUMP_GTID</span><span class="o">/</span><span class="n">COM_BINLOG_DUMP</span>
</span><span class='line'>     <span class="mi">4159</span>      <span class="k">while</span> <span class="o">(!</span><span class="n">io_slave_killed</span><span class="o">(</span><span class="n">thd</span><span class="o">,</span><span class="n">mi</span><span class="o">))</span>
</span><span class='line'>     <span class="mi">4160</span>      <span class="o">{</span>
</span><span class='line'>     <span class="mi">4169</span>           <span class="n">read_event</span><span class="err">，此为阻塞方法，会阻塞等待有新数据包传入</span>
</span><span class='line'>     <span class="mi">4184</span>          <span class="o">{</span>
</span><span class='line'>                         <span class="err">一些包错误的处理，包括</span><span class="n">packet</span> <span class="n">too</span> <span class="n">large</span> <span class="o">/</span> <span class="n">out</span> <span class="n">of</span> <span class="n">resource</span><span class="err">等</span>
</span><span class='line'>     <span class="mi">4213</span>          <span class="o">}</span>
</span><span class='line'>     <span class="mi">4219</span>          <span class="n">fire</span> <span class="n">HOOK</span> <span class="n">binlog_relay_io</span><span class="o">.</span><span class="na">after_read_event</span>
</span><span class='line'>     <span class="mi">4232</span>          <span class="n">queue_event</span><span class="err">，将</span><span class="n">event</span><span class="err">放入</span><span class="n">relay</span> <span class="n">log</span><span class="err">写</span><span class="n">buf</span>
</span><span class='line'>     <span class="mi">4240</span>          <span class="n">fire</span> <span class="n">HOOK</span> <span class="n">binlog_relay_io</span><span class="o">.</span><span class="na">after_queue_event</span>
</span><span class='line'>     <span class="mi">4250</span>          <span class="n">flush_master_info</span><span class="err">，将</span><span class="n">master_info</span><span class="err">和</span><span class="n">relay</span> <span class="n">log</span><span class="err">刷到</span><span class="n">disk</span><span class="err">上</span>
</span><span class='line'>                   <span class="err">此处，先刷</span><span class="n">relay</span> <span class="n">log</span><span class="err">，后刷</span><span class="n">master_info</span><span class="err">。这样意外的故障可以通过重连恢复机制来恢复。</span>
</span><span class='line'>                   <span class="err">若先刷</span><span class="n">master_info</span><span class="err">，后刷</span><span class="n">relay</span> <span class="n">log</span><span class="err">，意外故障时</span><span class="n">master_info</span><span class="err">已经更新，比如</span><span class="o">(</span><span class="mi">0</span><span class="o">-</span><span class="mi">100</span><span class="o">,</span> <span class="mi">100</span><span class="o">-</span><span class="mi">200</span><span class="o">)</span><span class="err">，而数据丢失，仅有</span><span class="o">(</span><span class="mi">0</span><span class="o">-</span><span class="mi">100</span><span class="o">)</span><span class="err">，恢复的</span><span class="n">replication</span><span class="err">会从</span><span class="mi">200</span><span class="err">开始。整个</span><span class="n">relay</span> <span class="n">log</span><span class="err">会成为</span><span class="o">(</span><span class="mi">0</span><span class="o">-</span><span class="mi">100</span><span class="o">,</span> <span class="mi">200</span><span class="o">-)</span><span class="err">，中间数据会丢失。</span>
</span><span class='line'>
</span><span class='line'>     <span class="mi">4286</span>          <span class="err">若</span><span class="n">relay</span> <span class="n">log</span><span class="err">达到容量限制，则</span><span class="n">wait_for_relay_log_space</span>
</span><span class='line'>     <span class="mi">4292</span>      <span class="o">}</span>
</span><span class='line'>     <span class="mi">4293</span> <span class="o">}</span>
</span><span class='line'>     <span class="mi">4296</span> <span class="err">之后都是收尾操作</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<h2>一些重点</h2>

<ol>
<li>此处不分析锁什么的，因为看不懂</li>
<li>4047 设置max_packet_size的目的不明</li>
<li>4073 开始slave会向master直接发送一些sql，然后解析返回。而不是包装在某个包的某个字段里，用一些预定义的变量来传递结果。<br/>这种设计一下就觉得山寨起来。<br/>后经同事 @神仙 指点，mysql这样做貌似是为了兼容性，免得数据包格式被改来改去。<br/>（看到mysql里大量的兼容代码都拿来处理包结构的问题，最极品的可能是莫过于LOG_EVENT_MINIMAL_HEADER_LEN了）<br/>在对流量影响不大的情况下，直接用sql反复查询的确是个好的解决手法</li>
<li>4250 将master_info和relay log刷到disk上。<br/>先刷relay log，后刷master_info。这样意外的故障可以通过relay log恢复机制来恢复。<br/>若先刷master_info，后刷relay log，意外故障时master_info已经更新，比如(0-100, 100-200)，而数据(100-200)丢失，仅有(0-100)，恢复的replication会从200开始。整个relay log会成为(0-100, 200-)，中间数据会丢失。</li>
</ol>


<h2>start slave时slave向master发送的事件</h2>

<ul>
<li><p>SELECT UNIX_TIMESTAMP() (rpl_slave.cc:get_master_version_and_clock)</p></li>
<li> SHOW VARIABLES LIKE &#8216;SERVER_ID&#8217; (rpl_slave.cc:get_master_version_and_clock)</li>
<li> SET @master_heartbeat_period=? (rpl_slave.cc:get_master_version_and_clock)</li>
<li> SET @master_binlog_checksum= @@global.binlog_checksum (rpl_slave.cc:get_master_version_and_clock)</li>
<li> SELECT @master_binlog_checksum (rpl_slave.cc:get_master_version_and_clock)</li>
<li> SELECT @@GLOBAL.GTID_MODE (rpl_slave.cc:get_master_version_and_clock)</li>
<li><p> SHOW VARIABLES LIKE &#8216;SERVER_UUID&#8217; （rpl_slave.cc:get_master_uuid）</p></li>
<li><p> SET @slave_uuid= &#8216;%s&#8217;（rpl_slave.cc:io_thread_init_commands)</p></li>
<li> COM_REGISTER_SLAVE(rpl_slave.cc:register_slave_on_master)</li>
<li> COM_BINLOG_DUMP(rpl_slave.cc:request_dump)</li>
</ul>


<h2>master与slave的时间差</h2>

<p>可以看到slave获得master的时间方法就是直接下sql，完全忽略网络延迟等等等等，属于不精准的时间</p>

<p><a href="http://guduwhuzhe.iteye.com/blog/1901707">这篇文章</a>从源码级别分析了Seconds_Behind_Master的来源，也给出了备库延迟跳跃的原因。总的来说就是Seconds_Behind_Master不可信。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mysql rpl_master.cc:mysql_binlog_send 源码的一些个人分析和吐槽]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2013/10/16/mysql-mysql_binlog_send-src/"/>
    <updated>2013-10-16T22:50:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2013/10/16/mysql-mysql_binlog_send-src</id>
    <content type="html"><![CDATA[<p>读了两天rpl_master.cc:mysql_binlog_send的源码（Mysql 5.6.11），总结一下</p>

<p>函数的入口是rpl_master.cc:com_binlog_dump，当slave向master请求数据时，在master上调用</p>

<p>函数参数说明: <br/>log_ident为slave请求的binlog文件名，如&#8221;mysql-bin.000001&#8221;<br/>pos为slave请求的binlog位置<br/>slave_gtid_executed为gtid相关，在此忽略</p>

<p>在此吐槽：</p>

<ol>
<li>这个函数将近1k行，且缩进混乱，代码折叠困难。最后附的我的笔记中，有整理好的源码下载</li>
<li>这个函数有两大段近百行的重复代码（1179 &amp; 1553）</li>
</ol>


<h1>源码的主体结构</h1>

<figure class='code'><figcaption><span>源码的主体结构  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">mysql_binlog_send</span><span class="o">(</span><span class="err">…</span><span class="o">)</span>
</span><span class='line'><span class="o">{</span>
</span><span class='line'>     <span class="mi">0814</span> <span class="err">…</span> <span class="n">bla</span> <span class="n">bla</span>
</span><span class='line'>     <span class="mi">1011</span> <span class="n">fake_rotate_event</span>
</span><span class='line'>     <span class="mi">1028</span> <span class="n">max_alloed_packet</span><span class="o">=</span> <span class="n">MAX_MAX_ALLOWED_PACKET</span>
</span><span class='line'>     <span class="mi">1038</span> <span class="k">if</span> <span class="o">(</span><span class="err">请求的</span><span class="n">POS</span><span class="err">不是从</span><span class="n">binlog</span><span class="err">开头开始</span><span class="o">)</span>
</span><span class='line'>     <span class="mi">1039</span> <span class="o">{</span>
</span><span class='line'>               <span class="err">从</span><span class="n">binlog</span><span class="err">开头中找到一个</span><span class="n">FD</span> <span class="n">event</span><span class="o">(</span><span class="n">FORMAT_DESCRIPTION_EVENT</span><span class="o">),</span> <span class="err">并发送给</span><span class="n">slave</span>
</span><span class='line'>     <span class="mi">1123</span> <span class="o">}</span>
</span><span class='line'>     <span class="mi">1124</span> <span class="k">else</span>
</span><span class='line'>     <span class="mi">1125</span> <span class="o">{</span>
</span><span class='line'>               <span class="n">FD</span> <span class="n">event</span><span class="err">可以从正常的</span><span class="n">replication</span><span class="err">中传送给</span><span class="n">slave</span><span class="err">，此处不做操作</span>
</span><span class='line'>     <span class="mi">1127</span> <span class="o">}</span>
</span><span class='line'>     <span class="mi">1132</span> <span class="k">while</span> <span class="o">(</span><span class="n">net</span><span class="err">和</span><span class="n">the</span><span class="err">都在运转</span><span class="o">)</span>
</span><span class='line'>     <span class="mi">1133</span> <span class="o">{</span>
</span><span class='line'>     <span class="mi">1143</span>      <span class="k">while</span> <span class="o">(</span><span class="err">从</span><span class="n">binlog</span><span class="err">中读取一个</span><span class="n">event</span><span class="o">)</span>
</span><span class='line'>     <span class="mi">1144</span>      <span class="o">{</span>
</span><span class='line'>     <span class="mi">1178</span>           <span class="k">switch</span> <span class="o">(</span><span class="n">event_type</span><span class="o">)</span>
</span><span class='line'>     <span class="mi">1179</span>           <span class="o">{</span>
</span><span class='line'>                         <span class="err">分类型处理</span><span class="n">event</span>
</span><span class='line'>     <span class="mi">1281</span>           <span class="o">}</span>
</span><span class='line'>     <span class="mi">1283</span>           <span class="err">若</span><span class="n">event</span><span class="err">需跳转到下一个</span><span class="n">binlog</span><span class="o">(</span><span class="n">goto_next_binlog</span><span class="o">),</span> <span class="k">break</span>
</span><span class='line'>     <span class="mi">1291</span>           <span class="n">fire</span> <span class="n">HOOK</span> <span class="n">before_send_event</span>
</span><span class='line'>     <span class="mi">1300</span>           <span class="err">记录</span><span class="n">skip_group</span>
</span><span class='line'>     <span class="mi">1306</span>           <span class="o">{</span>
</span><span class='line'>                         <span class="n">send</span> <span class="n">last</span> <span class="n">skip</span> <span class="n">group</span> <span class="n">heartbeat</span><span class="o">?</span>
</span><span class='line'>     <span class="mi">1326</span>           <span class="o">}</span>
</span><span class='line'>     <span class="mi">1331</span>           <span class="err">向</span><span class="n">slave</span><span class="err">发送</span><span class="n">event</span>
</span><span class='line'>     <span class="mi">1348</span>           <span class="o">{</span>
</span><span class='line'>                         <span class="err">处理</span><span class="n">LOAD_EVENT</span>
</span><span class='line'>     <span class="mi">1356</span>           <span class="o">}</span>
</span><span class='line'>     <span class="mi">1358</span>           <span class="n">fire</span> <span class="n">HOOK</span> <span class="n">after_send_event</span>
</span><span class='line'>     <span class="mi">1369</span>      <span class="o">}</span>
</span><span class='line'>     <span class="mi">1391</span>      <span class="k">if</span> <span class="o">(!</span><span class="n">goto_next_binlog</span><span class="o">)</span>
</span><span class='line'>     <span class="mi">1392</span>      <span class="o">{</span>
</span><span class='line'>                   <span class="err">发送完所有</span><span class="n">binlog</span><span class="err">，未发生</span><span class="n">binlog</span><span class="err">切换时</span>
</span><span class='line'>     <span class="mi">1437</span>          <span class="err">加锁尝试再读取一个</span><span class="n">event</span><span class="err">（此时其他进程不能更新</span><span class="n">binlog</span><span class="err">），目的是试探之前处理过程中</span><span class="n">master</span><span class="err">上是否有更多的</span><span class="n">binlog</span><span class="err">写入，若有，则跳转</span><span class="mi">1553</span><span class="err">处理</span><span class="n">read_packet</span>
</span><span class='line'>     <span class="mi">1451</span>          <span class="err">若没有更多的</span><span class="n">binlog</span>
</span><span class='line'>                   <span class="o">{</span>
</span><span class='line'>                        <span class="err">等待更多的</span><span class="n">binlog</span><span class="err">写入，等待时发送心跳</span>
</span><span class='line'>     <span class="mi">1545</span>          <span class="o">}</span>
</span><span class='line'>     <span class="mi">1553</span>          <span class="err">处理</span><span class="n">read_packet</span>
</span><span class='line'>                   <span class="o">{</span>
</span><span class='line'>                        <span class="err">分类型处理</span><span class="n">event</span>
</span><span class='line'>     <span class="mi">1682</span>          <span class="o">}</span>
</span><span class='line'>     <span class="mi">1683</span>      <span class="o">}</span>
</span><span class='line'>     <span class="mi">1685</span>      <span class="k">if</span> <span class="o">(</span><span class="n">goto_next_binlog</span><span class="o">)</span>
</span><span class='line'>               <span class="o">{</span>
</span><span class='line'>                    <span class="err">切换到下一个</span><span class="n">binlog</span>
</span><span class='line'>               <span class="o">}</span>
</span><span class='line'>     <span class="mi">1733</span> <span class="o">}</span>
</span><span class='line'>     <span class="mi">1735</span> <span class="err">之后是收尾处理</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<h1>重点步骤</h1>

<ol>
<li>补发Format Description event。<br/>如果传送从binlog开头开始，那么FD event会正常随着binlog传送；<br/>若传送不从binlog开头开始，则需要补发一个FD event，才开始传送</li>
<li>如何判断binlog读取完<br/>函数先不加锁读取binlog中的event，读完后，再加锁尝试读取一个event（加锁过程中，没有其他进程写进binlog），若有数据，则继续处理，若没有数据，则说明binlog读取完了，master会阻塞等待新的binlog写入。<br/>这样做主要为了：<br/>1. 不需要一直加锁读取binlog，保障性能；<br/>2. 无锁读取时会有其他进程写binlog，加锁可以保障这些新加的binlog得到妥善安置</li>
<li>心跳<br/>仅在不传送binlog时（master穷尽了binlog，开始阻塞等待新的binlog写入时）才进行心跳</li>
<li>Fake Rotate Event<br/>Fake Rotate Event在开始传送和切换binlog时发送到slave。主要作用是通知slave binlog filename，原因在源码comment里写的很清楚。但是很疑惑的是为什么在FD event里并没有binlog filename，这个问题发到了<a href="http://stackoverflow.com/questions/19375951/in-mysql-replication-why-format-description-event-doesnt-include-binlogs-name">StackoverFlow</a>，未有答案。（诶，看看我的stackoverflow的记录就知道，我的问题都是死题）</li>
</ol>


<h1>TODO</h1>

<p>有一些东西还是没弄懂，得慢慢读懂其他机制才可以，比如</p>

<ol>
<li>max_alloed_packet是如何作用的</li>
<li>send last skip group heartbeat的作用</li>
<li>不同类型的event的具体处理，需要和slave端结合在一起</li>
</ol>


<h1>我的笔记</h1>

<p>我的笔记<a href="https://app.yinxiang.com/shard/s11/sh/f23e9619-9c3d-47f5-a911-8945d0ee02a5/f4eb8539fb2f99e1481496c994b2c270">在此</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MHA failover时做了些啥]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2013/10/14/mha-failover/"/>
    <updated>2013-10-14T21:39:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2013/10/14/mha-failover</id>
    <content type="html"><![CDATA[<p>读了MHA failover部分的源码整理一下</p>

<p>代码位置注解的格式为file_name@function_name</p>

<h1>设定场景</h1>

<p>假设集群里有四个mysql实例分别是old_master和slave 0,1,2
slave 0,1,2 执行failover中的角色分别为 Latest slave, Oldest slave 和 New master</p>

<p>如图
<img src="http://ikarishinjieva.github.com/blog/images/2013-10-14-mha-failover-1.png"></p>

<h1>Failover的步骤代码</h1>

<p>(MasterFailover@do_master_failover)</p>

<p> 1  check_settings</p>

<p> 2  force_shutdown</p>

<p> 3.1    check_set_latest_slaves</p>

<p> 3.2    save_master_binlog</p>

<p> 3.3    Determining New Master Phase</p>

<pre><code>3.3.1 find_latest_base_slave

3.3.2 select_new_master

3.3.3 recover_master

3.3.4 $new_master-&gt;{activated} = 1;
</code></pre>

<p> 4  Slaves Recovery Phase</p>

<p>   4.1 Starting Parallel Slave Diff Log Generation Phase.</p>

<p>   4.2 Starting Parallel Slave Log Apply Phase.</p>

<p> 5  cleanup</p>

<h1>Failover的一些步骤说明</h1>

<p>2  force_shutdown</p>

<pre><code>2.1  对所有slave, stop io thread.(MasterFailover@force_shutdown) 这里仅stop io thread, 而不是stop slave, 尽可能让sql thread运行。sql thread是在recover必要时（要生成差异数据时）才停下。 

2.2  在Old master上回收动态ip, shutdown（并可选用power manager对Old master进行关机）. (MasterFailover@force_shutdown_internal)
</code></pre>

<p>3.1  check_set_latest_slaves, 确定latest_slave和oldest_slaves. latest_slave指的是slave中relay log最超前的slave, 相反oldest_slave指的是relay log最落后的slave</p>

<p>3.2  save_master_binlog, 保存Latest slave到Old master的binlog差异数据, 如图中蓝色部分. 由于master可能是硬件故障等, 不一定能响应save_master_binlog, 所以蓝色部分不一定能保存下来. 若失败, 之后的步骤中用到蓝色部分的地方都可以忽略, 最终结果也是会有部分数据的丢失</p>

<p>3.3.1  find_latest_base_slave, 这里最理想的状况是能从所有的latest slave中能找到一个relay log可以用于补齐oldest slave的 （如果oldest slave可以被补齐, 那其他的slave都可以被补齐）. 如场景图中所示，Slave 0可以作为latest_base_slave.</p>

<p>另一种情况是不能用于补齐oldest slave, 比如下图的状况, 集群里最全最新的relay log也无法和oldest slave对接上. 这种情况的处理跟ignore_fail配置有关, 若所有努力都失败只好failover失败</p>

<p>关于ignore_fail的处理逻辑，可参看源码或者文后我附的源码笔记
<img src="http://ikarishinjieva.github.com/blog/images/2013-10-14-mha-failover-2.png"></p>

<p>3.3.2  select_new_master, 选举new master.</p>

<p>选举的策略是尽量在candidate slave列表中，尽量在latest slave列表中，不可以在bad列表中. 注意，new master可以不是latest slave, 场景图中列举的是这种情况（尽管应该比较少见）</p>

<p>3.3.3  recover_master. 将差异数据补齐到new master, 让new master成为集群里数据最全最新的节点.</p>

<p>生成old_master上exec relay_log到read relay_log的差异数据（原因是sql thread落后于io thread）, 源码中中称为diff_from_exec_to_read, 如图中绿色部分.</p>

<p>生成old_master到latest_base_slave的差异数据(MasterFailover@recover_relay_logs), 如图中黄色部分.</p>

<p>重放: 在old_master上重放绿色部分, 然后重放黄色部分(MasterFailover@send_binlog &amp; MasterFailover@recover_slave), 最后重放蓝色部分（MasterFailover@apply_diff）</p>

<p>4  对所有的slave, 这里是以old_slave为例, 与recover_master类似：生成diff_from_exec_to_read（黑色部分）, 生成与latest_base_slave的差异数据（红色部分）. 然后重放黑色部分，红色部分和蓝色部分. (MasterFailover@recover_slaves)</p>

<p>最后让所有slave连到新的master上</p>

<h1>一点说明</h1>

<ol>
<li>只是简单记录了failover的基本操作, 仅在2.1里说明了stop io thread. 代码中其他操作如change master的操作可以直接翻代码翻到, 不穷举</li>
<li>我阅读代码的原始笔记放在<a href="https://app.yinxiang.com/shard/s11/sh/565c2973-fae1-452c-9f3e-8418fbb04360/11b9fd4b99229f8599c8c96a7bc3c72e">evernote公开页面</a>, 里面有一些细节, 不再整理</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[jruby backtick + jre 6 会卡住]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2013/10/11/jruby-175-jre-6-stdin-bug/"/>
    <updated>2013-10-11T22:03:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2013/10/11/jruby-175-jre-6-stdin-bug</id>
    <content type="html"><![CDATA[<p>最近在jruby 1.7.5 + jre 6上碰到的土亢</p>

<h1>现象</h1>

<p>用backtick调用命令，比如</p>

<figure class='code'><figcaption><span>用backtick调用命令  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="sb">`./some_script`</span>
</span></code></pre></td></tr></table></div></figure>


<p>在调用命令之前/同时在terminal输入一些回车，有一定概率backtick的调用会卡住不返回。
此时再输入一个回车，调用会继续执行并返回。</p>

<h1>解决</h1>

<p>一切靠猜</p>

<p>jruby有个bug：<a href="http://jira.codehaus.org/browse/JRUBY-4626">Gaps in STDIN pipe stream if backtick is used</a></p>

<p>Charles Oliver Nutter在comment中写到&#8221;For JRuby 1.7pre1 on Java 7, this should be fixed; TTY should be handled correctly. For other Java versions, we can&#8217;t fix this.&#8221;，于是最方便的就是升级jre到7</p>

<p>经验证升级jre可以从土亢中爬出来。
如果难以升级jre，参看<a href="https://www.ruby-forum.com/topic/4413754">这里</a>，这个兄弟做了很全的测试。可以用IO.popen或者Open3.popen3替换backtick。</p>

<h1>经验</h1>

<p>jruby有坑，同时也提供了便捷的手段将现有的java项目改成比较爽的样子。这些坑是难以预料的，做好准备，然后一如既往踩过去。</p>
]]></content>
  </entry>
  
</feed>
