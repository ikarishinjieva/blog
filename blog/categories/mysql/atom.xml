<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: mysql | Tac say]]></title>
  <link href="http://ikarishinjieva.github.com/blog/blog/categories/mysql/atom.xml" rel="self"/>
  <link href="http://ikarishinjieva.github.com/blog/"/>
  <updated>2014-04-17T22:47:06+08:00</updated>
  <id>http://ikarishinjieva.github.com/blog/</id>
  <author>
    <name><![CDATA[Tac Huang (ikari_shinji@github)]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[PREVIOUS_GTIDS_LOG_EVENT的格式]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2014/04/17/PREVIOUS_GTIDS_LOG_EVENT/"/>
    <updated>2014-04-17T22:08:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2014/04/17/PREVIOUS_GTIDS_LOG_EVENT</id>
    <content type="html"><![CDATA[<p>并没找到特别好的对<code>PREVIOUS_GTIDS_LOG_EVENT</code>格式的描述, 自己写一个</p>

<p>据下面这个例子, 是<code>mysqlbinlog</code>的分析结果</p>

<pre><code># at 120
#140417 15:50:36 server id 904898000  end_log_pos 311 CRC32 0x311ec069
# Position  Timestamp   Type   Master ID        Size      Master Pos    Flags
#       78 cc 87 4f 53   23   d0 a5 ef 35   bf 00 00 00   37 01 00 00   00 00
#       8b 04 00 00 00 00 00 00 00  7e 23 40 1a c6 03 11 e3 |................|
#       9b 8e 13 5e 10 e6 a0 5c fb  01 00 00 00 00 00 00 00 |................|
#       ab 01 00 00 00 00 00 00 00  06 00 00 00 00 00 00 00 |................|
#       bb 81 86 fc 1e c5 ff 11 e3  8d f9 e6 6c cf 50 db 66 |...........l.P.f|
#       cb 01 00 00 00 00 00 00 00  01 00 00 00 00 00 00 00 |................|
#       db 0c 00 00 00 00 00 00 00  a6 ce 32 8c c6 02 11 e3 |..........2.....|
#       eb 8e 0d e6 6c cf 50 db 66  01 00 00 00 00 00 00 00 |...l.P.f........|
#       fb 01 00 00 00 00 00 00 00  07 00 00 00 00 00 00 00 |................|
#      10b b7 00 99 20 c6 01 11 e3  8e 07 5e 10 e6 a0 5c fb |................|
#      11b 01 00 00 00 00 00 00 00  01 00 00 00 00 00 00 00 |................|
#      12b 07 00 00 00 00 00 00 00  69 c0 1e 31             |........i..1|
#      Previous-GTIDs
# 7e23401a-c603-11e3-8e13-5e10e6a05cfb:1-5,
# 8186fc1e-c5ff-11e3-8df9-e66ccf50db66:1-11,
# a6ce328c-c602-11e3-8e0d-e66ccf50db66:1-6,
# b7009920-c601-11e3-8e07-5e10e6a05cfb:1-6
</code></pre>

<p>从78-8a的位置, 是Binlog Event header, 参看<a href="http://dev.mysql.com/doc/internals/en/binlog-event-header.html">这里</a></p>

<p>最后四个字节, (69 c0 1e 31) 是checksum, 与参数 <a href="http://dev.mysql.com/doc/refman/5.6/en/replication-options-binary-log.html#option_mysqld_binlog-checksum">binlog-checksum</a> 有关</p>

<p>中间的部分, 是gtid的数据区, 格式如下:</p>

<table>
<thead>
<tr>
<th>层次 </th>
<th> 字节数 </th>
<th> 含义 </th>
<th> 例子中的数值</th>
</tr>
</thead>
<tbody>
<tr>
<td>0 </td>
<td> 8 </td>
<td> GTID中sid-number的组数 </td>
<td> 例子中为四组</td>
</tr>
<tr>
<td>1 </td>
<td> 16 </td>
<td> 第一组sid-number的sid部分 </td>
<td> 例子中为(7e 23 40 1a c6 03 11 e3 9b 8e 13 5e 10 e6 a0 5c fb)</td>
</tr>
<tr>
<td>1 </td>
<td> 8 </td>
<td> 第一组sid-number中, internal numbers的个数 </td>
<td> 例子中为1个internal number (<code>1-5</code>)</td>
</tr>
<tr>
<td>2 </td>
<td> 8 </td>
<td> 第一组sid-number中, 第一个internal number的起始number </td>
<td> 例子中为<code>1</code></td>
</tr>
<tr>
<td>2 </td>
<td> 8 </td>
<td> 第一组sid-number中, 第一个internal number的结束number+1 </td>
<td> 例子中为<code>5+1=6</code></td>
</tr>
<tr>
<td>2 </td>
<td> 8 </td>
<td> 第一组sid-number中, 第二个internal number的起始number </td>
<td> ... (例子中没有第二个internal number)</td>
</tr>
<tr>
<td>2 </td>
<td> 8 </td>
<td> 第一组sid-number中, 第二个internal number的结束number+1 </td>
<td> ... (例子中没有第二个internal number)</td>
</tr>
<tr>
<td>... </td>
<td> ... </td>
<td> ... </td>
<td> ...</td>
</tr>
<tr>
<td>1 </td>
<td> 16 </td>
<td> 第二组sid-number的sid部分 </td>
<td> ...</td>
</tr>
<tr>
<td>... </td>
<td> ... </td>
<td> ... </td>
<td> ...</td>
</tr>
</tbody>
</table>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MDL_map_partition中对锁的过渡]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2014/04/05/MDL_map_partition-lock-split/"/>
    <updated>2014-04-05T11:43:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2014/04/05/MDL_map_partition-lock-split</id>
    <content type="html"><![CDATA[<p>在<code>MDL</code>源码中有一段<code>MDL_map_partition</code>中对锁的过渡有点意思, 拿出来分析一下</p>

<h4>场景</h4>

<p><code>MDL_map_partition</code>是容纳<code>MDL_lock</code>的一个容器, <code>MDL_lock</code>可以简单的理解为一种锁.</p>

<p>那么场景问题是现在我要从锁容器<code>C</code>中查找一个锁<code>L</code>并加锁<code>L</code>, 怎样做到多线程安全</p>

<p>场景中<code>C</code>上有保护<code>C</code>的锁<code>A</code> (容器锁), <code>L</code>上的锁为<code>B</code> (成员锁) (此处做了简化, 实际上<code>MDL_lock</code>并不是一个锁, 而是类似于条件变量, 而锁<code>B</code>是保护<code>L</code>的锁. 此处将<code>L</code>简化为一把锁)</p>

<h4>分析1</h4>

<p>最简单的方法, 就是<code>A</code>加锁, <code>B</code>加锁, <code>A</code>解锁. 这种方法肯定不会有错, 但是并发性上会出现问题. 比如以下场景</p>

<ol>
<li>线程T1持有<code>B</code></li>
<li>线程T2正在容器中查找<code>B</code>.</li>
<li>线程T3在同一个容器中查找另外一个<code>MDL_lock</code></li>
</ol>


<p>T2先将<code>A</code>加锁, 加锁<code>B</code>时, 由于T1持有<code>B</code>, T2被阻塞; T3在同一个容器中查找另一个不相关的成员, 先要加锁<code>A</code>, <code>A</code>被T2持有, T3被阻塞</p>

<p>因此, 这种做法的并发性很差</p>

<h4>分析2</h4>

<p>提高并发性的关键是将<code>A</code>锁过渡到<code>B</code>锁, 比如这样: <code>A</code>加锁, 查找<code>B</code>, <code>A</code>解锁, <code>B</code>加锁.</p>

<p>这种方法解决了并发性, 但显而易见形成了一个无锁区 (从<code>A</code>解锁到<code>B</code>加锁这个区域). 如果在无锁区另一个线程将<code>B</code>销毁或移出容器, 那么后面的<code>B</code>加锁操作就会悲剧</p>

<h4>分析3</h4>

<p>面对无锁区的问题, 可以试着加<code>version</code>(版本变量)来解决, 规则如下:</p>

<ul>
<li>任何将成员移入/移出容器的情况, 都需要获得容器锁<code>A</code>和成员锁<code>B</code>, 并在元素<code>version</code>上加1</li>
<li>对成员的销毁, 需要先将成员移出容器</li>
</ul>


<p>这样, 查找成员的流程变为:</p>

<ol>
<li>线程T1, 对<code>A</code>加锁, 找到<code>B</code>, 记录<code>B</code>的<code>version</code>, 记为v1. 对<code>A</code>解锁</li>
<li>线程T2, <code>B</code>销毁或移出容器, 需要获得<code>A</code>和<code>B</code>锁, 对<code>version</code>加1, 记为v2</li>
<li>线程T1, 等到T2释放<code>B</code>锁后, 可获得<code>B</code>锁, 发现<code>v1 != v2</code>, 意味着成员可能在容器中已经被移出或销毁, 则需要重试整个过程</li>
</ol>


<p>加入<code>version</code>后, 对于销毁成员的场景, 并发性并没有改变 (因为仍然需要同时获得两把锁), 但对于查找成员的场景, 并发性和分析2一样</p>

<p>不幸的是, 这个场景仍然存在问题, 很容易看到其中一个逻辑问题, T1在T2销毁<code>B</code>锁后, 还获得了<code>B</code>锁. 也就是T2不能即刻销毁<code>B</code>锁, 否则所有等待<code>B</code>锁的线程都会悲剧. 那<code>B</code>锁何时能被安全销毁</p>

<h4>分析4</h4>

<p>要解决分析3的问题, 可以在<code>B</code>上添加引用计数, 细节如下:</p>

<ul>
<li>在成员未被移出容器时, 持有<code>A</code>锁可以对成员引用计数<code>usage_count</code>进行加1, 即在容器中查找成员时, 容器负责对成员的<code>usage_count</code>加1</li>
<li>持有<code>B</code>锁可以对自己的解引用计数<code>release_count</code>进行加1, 即使用者在使用完<code>B</code>后, 对<code>B</code>进行解引用</li>
<li>如果<code>usage_count</code> == <code>release_count</code>, 则<code>B</code>可以被安全销毁</li>
</ul>


<p>可以看到<code>usage_count</code>和<code>release_count</code>在分别在不同锁的保护下, 代入分析3的场景, 发现可以解决分析3的问题</p>

<p>还有一些需要说明的边界情况</p>

<ul>
<li>在成员已经被移出容器后, 成员引用计数<code>usage_count</code>不再受<code>A</code>锁保护, 而是受<code>B</code>锁保护. 相当于容器已经不再管理成员的引用计数</li>
<li>如何判断"成员已经被移出容器", 可以在成员上添加状态量<code>is_removed_from_container</code>, 读取此状态需要<code>A</code>锁或<code>B</code>锁, 修改此状态需要<code>A</code>锁和<code>B</code>锁.</li>
</ul>


<h4>Mysql的实现</h4>

<p>Mysql的实现和之前的分析大致相同, 给出映射表</p>

<table>
<thead>
<tr>
<th>分析里的概念 </th>
<th> Mysql的变量</th>
</tr>
</thead>
<tbody>
<tr>
<td>版本变量<code>version</code> </td>
<td> <code>MDL_lock.m_version</code></td>
</tr>
<tr>
<td>成员引用计数<code>usage_count</code> </td>
<td> <code>MDL_lock.m_ref_usage</code></td>
</tr>
<tr>
<td>成员解引用计数<code>release_count</code> </td>
<td> <code>MDL_lock.m_ref_release</code></td>
</tr>
<tr>
<td>状态量<code>is_removed_from_container</code> </td>
<td> <code>MDL_lock.m_is_destroyed</code></td>
</tr>
</tbody>
</table>


<p>实现锁拆分的函数为<code>MDL_map_partition::move_from_hash_to_lock_mutex</code>, 一看就懂</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[整理一下最近读的MDL源码]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2014/04/04/MDL/"/>
    <updated>2014-04-04T20:00:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2014/04/04/MDL</id>
    <content type="html"><![CDATA[<p>以下都是个人理解, 如有疏漏请斧正
另, 因为理解不深, 将忽略锁级别以及锁共享的细节</p>

<h2>MDL</h2>

<p>MDL (Metadata lock), 除了正常的Condition var提供的功能外, 还额外提供了
1. 不同的锁级别. 在不冲突的情况下, 允许共享资源
2. 死锁检查和处理
3. 记录等待状态, 是死锁检查的基础</p>

<h2>模型</h2>

<p><code>MDL_lock</code> 表示Mysqld中的一个资源(库/表/...) 存储在全局结构 <code>mdl_locks (MDL_map)</code>中, <code>mdl_locks</code>内有<code>m_partitions</code> (锁的分区), 用来分散查找lock时的竞争</p>

<p><code>MDL_context</code> 为MDL上下文接口, 表示一个资源竞争者, THD实现了这个接口, 即一个Mysqld的线程可以是<code>MDL_lock</code>的资源竞争者</p>

<p><code>MDL_ticket</code> 表示<code>MDL_lock</code>的许可或请求, 会同时挂在两处:</p>

<ol>
<li>挂在所属<code>MDL_Context</code>中, 通过<code>MDL_ticket.next_in_context/prev_in_context</code>组织链表</li>
<li>挂在<code>MDL_lock</code>的队列中, 通过<code>MDL_ticket.next_in_lock/prev_in_lock</code>组织链表. <code>MDL_lock</code>的队列分为两种, 一个<code>MDL_ticket</code>可能会挂在其中之一

<ul>
<li>挂在<code>MDL_lock</code>的等待队列(<code>MDL_lock.m_waiting</code>)中, 表示<code>MDL_ticket</code>的owner (<code>MDL_context</code>)正在等待该资源(<code>MDL_lock</code>)</li>
<li>挂在<code>MDL_lock</code>的已许可队列(<code>MDL_lock.m_granted</code>)中, 表示<code>MDL_ticket</code>的owner (<code>MDL_context</code>)已经获得该资源(<code>MDL_lock</code>)</li>
</ul>
</li>
</ol>


<p>总结一下, <code>MDL_context</code>和<code>MDL_ticket</code>的关系是一对多, 一个竞争者可以同时申请/获得多个资源的许可; <code>MDL_ticket</code>和<code>MDL_lock</code>的关系是多对一, 可以同时有多个资源许可在竞争一个资源, 或者多个资源许可可以<em>有条件</em>地共享一个资源</p>

<h2>如何获得锁</h2>

<p>简单分析<code>MDL_context::acquire_lock</code>方法, 其主要流程是</p>

<pre><code>bool MDL_context::acquire_lock(MDL_request *mdl_request, ulong lock_wait_timeout) {
    ...

    try_acquire_lock_impl(...) 
    //尝试不等待立刻获得资源, 如果成功直接返回
    //以下是等待资源的处理
    ...
    lock-&gt;m_waiting.add_ticket(ticket) 
    //将一个资源申请`ticket`挂入资源`lock`的等待队列`m_waiting`
    if (lock-&gt;needs_notification(ticket)) {
        //如果等待资源时需要通知状态, 则不断轮询并通知
        //将忽略此处的细节
        ...
    } else {
        //等待资源
        //结果可能是获得资源, 或者超时, 或者异常 (比如被死锁检测机制判定死亡)
        //`timed_wait`中的实现是等待COND(条件变量)`m_wait.m_COND_wait_status`
        wait_status= m_wait.timed_wait(...);
    }
    //收尾处理
    m_tickets[mdl_request-&gt;duration].push_front(ticket)
    //将资源申请`ticket`挂入`MDL_Context.m_tickets`
    ...
}
</code></pre>

<h3>记录等待状态</h3>

<p>之前提到了记录等待状态, 在<code>MDL_context::acquire_lock</code>方法中可以看到如下代码 (上一节未列出)</p>

<pre><code>bool MDL_context::acquire_lock(MDL_request *mdl_request, ulong lock_wait_timeout) {
    m_wait.reset_status();
    ...
    will_wait_for(ticket); //其中设置了`m_waiting_for`
    if (lock-&gt;needs_notification(ticket)) {
        ...
        //等待资源
        wait_status= m_wait.timed_wait(m_owner, &amp;abs_timeout, TRUE,
                                  mdl_request-&gt;key.get_wait_state_name());
    } else {
        //等待资源
        wait_status= m_wait.timed_wait(m_owner, &amp;abs_timeout, TRUE,
                                  mdl_request-&gt;key.get_wait_state_name());
    }
    done_waiting_for(); //其中清空了`m_waiting_for`
    ...
}
</code></pre>

<p>可以看到<code>MDL_context.m_wait</code>是用来等待资源的工具类, 其中进行等待处理, 并记录等待资源的状态/结果.</p>

<p>还有一个<code>MDL_context.m_waiting_for</code>也在记录<code>MDL_context</code>正在进行的资源申请(<code>MDL_ticket</code>), 其正在等待某个资源. 实际上<code>m_waiting_for</code>是冗余的信息, 至于原因源代码中有解释, 此处不冗余说明...</p>

<h2>如何释放锁</h2>

<p>释放锁, 需要完成下面几个动作:</p>

<ol>
<li>将<code>ticket</code>从<code>MDL_lock</code>的数据结构上卸下来</li>
<li>调度选择新的锁占有者</li>
<li>将<code>ticket</code>从<code>MDL_context</code>的数据结构上卸下并回收</li>
</ol>


<p>入口为<code>MDL_context::release_lock</code></p>

<pre><code>void MDL_context::release_lock(enum_mdl_duration duration, MDL_ticket *ticket) 
{
    ...
    lock-&gt;remove_ticket(&amp;MDL_lock::m_granted, ticket) {
        //将`ticket`从`MDL_lock`的数据结构上卸下来
        (this-&gt;*list).remove_ticket(ticket);
        ...
        //调度选择新的锁占有者
        reschedule_waiters();
    }()

    //将`ticket`从`MDL_context`的数据结构上卸下并回收
    m_tickets[duration].remove(ticket);
    MDL_ticket::destroy(ticket);
    ...
}
</code></pre>

<p>下面说明调度的细节</p>

<h3>释放锁时的调度</h3>

<p>调度函数的入口是<code>MDL_lock::reschedule_waiters</code></p>

<p>最简单的调度就是从<code>MDL_lock.m_waiting</code>队列中取出头元素, 直接将资源调度给头元素即可</p>

<p>Mysqld在此基础上添加了一个退让条件:
如果资源连续被<em>高优先级</em>(比如<code>SNW</code>/<code>SNRW</code>/<code>X</code>锁类型)的<code>ticket</code>获得, 那么退让一步, 允许资源间隔被调度给<em>低优先级</em>的<code>ticket</code>防止其饿死.</p>

<p>用<code>MDL_lock::reschedule_waiters</code>的代码说就是, 如果<code>MDL_lock</code>被连续分配给<code>hog_lock_types_bitmap()</code>中定义的<em>高优先级</em>类型的<code>ticket</code>,连续的次数<code>m_hog_lock_count</code>超过<code>max_write_lock_count</code>, 那么开启退让条件, 批准第一个<em>非</em><em>高优先级</em>的<code>ticket</code>获得资源</p>

<h2>死锁检测</h2>

<p>死锁检测的入口是<code>MDL_context::find_deadlock</code>, 本身原理很简单, 但源码写的很复杂= =. 先说明原理, 再对应源码</p>

<p>设当前<code>MDL_context</code>为图的一个节点<code>A</code>, 从节点<code>A</code>出发,  找到<code>A</code>的正在等待的资源<code>L</code>(<code>A.m_waiting_for.m_lock</code>)中的<code>m_granted</code>里的每一个<code>MDL_ticket</code>对应的<code>MDL_context</code> <code>B</code>, 表示<code>A</code>正在等待<code>B</code>释放资源<code>L</code>. 在图中<code>A</code> -> <code>B</code> 添加一条有向边</p>

<p>死锁检查的工作就是遍历这张有向图, 检查其是否存在环路</p>

<p>以<code>MDL_context::find_deadlock</code>入口, 展开一些调用来说明代码</p>

<pre><code>(MDL_context::find_deadlock)
while(1) {
    visit_subgraph(visitor) {
        m_waiting_for-&gt;accept_visitor(visitor) {
            m_lock-&gt;visit_subgraph(this, visitor) {
                ...
            }()
        }()
    }()
    break if no deadlock
    set deadlock victim
    break if deadlock victim is current context
}
</code></pre>

<p>可以看到<code>find_deadlock</code>以<code>MDL_context.m_waiting_for.m_lock</code>为起始点, 不断遍历其有向图, 选出victim. 直到
* 没有发现死锁
* 或自己被选为victim</p>

<p>其使用一个visitor (<code>MDL_wait_for_graph_visitor</code>) 贯穿遍历过程, 其记录了遍历的过程</p>

<p>再来看<code>MDL_lock::visit_subgraph</code>, 此函数是以一个<code>MDL_lock</code>为起点, 来遍历依赖图</p>

<pre><code>MDL_lock::visit_subgraph(MDL_ticket *waiting_ticket, MDL_wait_for_graph_visitor *gvisitor) {

    //此处是因为MDL_context.m_waiting_for是冗余信息, 但无法保证更新同步, 带来的额外操作. 忽略此处细节
    if (src_ctx-&gt;m_wait.get_status() != MDL_wait::EMPTY) {...}

    //visitor用来记录遍历层次
    //当遍历层次大于MAX_SEARCH_DEPTH(32), 也认为发现死锁
    if (gvisitor-&gt;enter_node(src_ctx)) {...}

    //由于现在是以一个资源(`MDL_lock`)为视角, 之后的检查为了效率, 遍历会从两个方向同时进行, 即检查节点的出度方向(`MDL_lock.m_granted`)和节点的入度方向(`MDL_lock.m_waiting`). 


    //为了效率, 死锁检测会先检测距离为1的临近节点, 而先不深度遍历图

    while ((ticket= granted_it++))
    {
      if (ticket-&gt;get_ctx() != src_ctx &amp;&amp;
          ticket-&gt;is_incompatible_when_granted(waiting_ticket-&gt;get_type()) &amp;&amp;
          gvisitor-&gt;inspect_edge(ticket-&gt;get_ctx()))
      {
        goto end_leave_node;
      }
    }

    while ((ticket= waiting_it++))
    {
      /* Filter out edges that point to the same node. */
      if (ticket-&gt;get_ctx() != src_ctx &amp;&amp;
          ticket-&gt;is_incompatible_when_waiting(waiting_ticket-&gt;get_type()) &amp;&amp;
          gvisitor-&gt;inspect_edge(ticket-&gt;get_ctx()))
      {
        goto end_leave_node;
      }
    }

    //此处开始, 深度遍历图

    granted_it.rewind();
    while ((ticket= granted_it++))
    {
      if (ticket-&gt;get_ctx() != src_ctx &amp;&amp;
          ticket-&gt;is_incompatible_when_granted(waiting_ticket-&gt;get_type()) &amp;&amp;
          ticket-&gt;get_ctx()-&gt;visit_subgraph(gvisitor))
      {
        goto end_leave_node;
      }
    }

    waiting_it.rewind();
    while ((ticket= waiting_it++))
    {
      if (ticket-&gt;get_ctx() != src_ctx &amp;&amp;
          ticket-&gt;is_incompatible_when_waiting(waiting_ticket-&gt;get_type()) &amp;&amp;
          ticket-&gt;get_ctx()-&gt;visit_subgraph(gvisitor))
      {
        goto end_leave_node;
      }
    }
    ...

    //visitor退栈
    gvisitor-&gt;leave_node(src_ctx);
    ...
}
</code></pre>

<p>发现死锁后, 会调用<code>Deadlock_detection_visitor::opt_change_victim_to</code>, 其中进行<code>MDL_context</code>权重比较, 来选取一个作为victim, 此处忽略细节</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[对Mysql bug #70307 的再学习]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2014/04/01/study-mysql-bug-70307-2/"/>
    <updated>2014-04-01T13:07:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2014/04/01/study-mysql-bug-70307-2</id>
    <content type="html"><![CDATA[<p>之前对bug #70307有过<a href="http://ikarishinjieva.github.io/blog/blog/2013/10/25/study-mysql-bug-70307/">学习</a>, 苦于阿兹海默状态, 又花了半天在mysql 5.5.33上探查这个场景的原因...</p>

<p>简单记录一下</p>

<h4>现象</h4>

<p>mysql进行主从复制, 从机上<code>FLUSH TABLES WITH READ LOCK</code>后, 进行<code>STOP SLAVE</code>, 一定概率下 <code>SHOW SLAVE STATUS</code>卡住</p>

<h4>重现步骤</h4>

<table>
<thead>
<tr>
<th>master </th>
<th> slave client 1 </th>
<th> slave client 2</th>
</tr>
</thead>
<tbody>
<tr>
<td> - </td>
<td> STOP SLAVE IO_THREAD </td>
<td> -</td>
</tr>
<tr>
<td> CREATE TABLE TEST.TEST ... </td>
<td> - </td>
<td> -</td>
</tr>
<tr>
<td> - </td>
<td> FLUSH TABLES WITH READ LOCK </td>
<td> -</td>
</tr>
<tr>
<td> - </td>
<td> START SLAVE IO_THREAD </td>
<td> -</td>
</tr>
<tr>
<td> - </td>
<td> - </td>
<td> STOP SLAVE</td>
</tr>
<tr>
<td> - </td>
<td> SHOW SLAVE STATUS </td>
<td> -</td>
</tr>
</tbody>
</table>


<p>其中, <code>START/STOP SLAVE IO_THREAD</code>是为了在<code>FLUSH TABLES WITH READ LOCK</code>时造成slave io_thread有未提交数据</p>

<h4>死锁原因</h4>

<ol>
<li><code>FLUSH TABLES WITH READ LOCK</code> 会阻塞IO_THREAD提交数据</li>
<li><code>STOP SLAVE</code>会等待IO_THREAD结束 (<code>mi-&gt;stop_cond</code>), 即<code>STOP SLAVE</code>间接被<code>FLUSH TABLES WITH READ LOCK</code>阻塞</li>
<li><code>STOP SLAVE</code>在被阻塞前, 持有了<code>LOCK_active_mi</code>, 独占了<code>master_info</code></li>
<li><code>SHOW SLAVE STATUS</code>会申请锁<code>LOCK_active_mi</code>, 被<code>STOP SLAVE</code>阻塞</li>
<li>如果<code>SHOW SLAVE STATUS</code>是由之前<code>FLUSH TABLES WITH READ LOCK</code>的<code>slave client 1</code>发出的, 那逻辑上相当于自己在等待自己释放资源</li>
<li>从另外的client上<code>UNLOCK TABLES</code>也解不开</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[mysql, 利用假master重放binlog]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2014/03/26/mysql-fake-master-server/"/>
    <updated>2014-03-26T20:08:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2014/03/26/mysql-fake-master-server</id>
    <content type="html"><![CDATA[<h4>场景</h4>

<p>这次想解决的场景是想在一个mysqld实例上重放一些来自于其他实例的binlog, 传统的方法是<code>mysqlbinlog</code>. 但是<code>mysqlbinlog</code>会带来一些问题, 比如这个<a href="http://bugs.mysql.com/bug.php?id=33048">bug</a></p>

<p>后同事转给我一种利用<a href="http://www.orczhou.com/index.php/2013/11/use-mysql-replication-to-recove-binlog/">复制重放binlog的方法</a>, 其中提到两种方式:</p>

<ul>
<li>第一种是修改relay log的信息, 将binlog作为relay log来放. 这是种很好的方法, 缺点是<code>mysqld</code>需要停机重启. 如果不重启, server中对于<code>relay-log.index</code>和<code>relay-log.info</code>等的缓存不会刷新.</li>
<li>第二种是起另外一个mysqld实例, 将binlog作为relay log, 再将此实例作为master, 向目标实例进行复制. 这种方式的缺点是作为中间人的mysqld实例需要消耗资源</li>
</ul>


<p>于是想办法将第二种方法进行改进, 即制造一个假的master, 实现简单的复制协议, 直接将binlog复制给目标mysqld实例. 与第二种方式相比, 好处在于只使用少量资源 (一个端口, 一点用来读文件的内存).</p>

<h4>实现</h4>

<p>实现参看我的<a href="https://github.com/ikarishinjieva/mysql_binlog_utils/blob/master/fake_master_server.go">github</a></p>

<p><strong>注意: 此实现仅适用于mysql 5.5.33, 其它版本未测试</strong></p>

<p>由于<a href="http://dev.mysql.com/doc/internals/en/client-server-protocol.html">mysql internals</a> 已经将mysql的网络协议写的比较详细, 需要做的只是起一个tcp的server, 同目标mysqld实例进行交互即可.</p>

<p>此处逐层介绍实现, 将忽略不需要特别注意的部分. 为了简单, 将binlog的来源mysqld实例称为A, 目标mysqld实例称为B, 假master称为T.</p>

<p>目标就是讲从A获得的binlog文件, 通过T, 在B上重放出来</p>

<p>从B发起<code>start slave</code>, 到T真正向B复制数据, 需要下面两个阶段</p>

<h5>1. Handshake Phase</h5>

<h5>2. Replication Phase</h5>

<p>先介绍Handshake Phase, 有以下步骤</p>

<h5>1.1 B执行<code>start slave</code>, 此时B向T建立一个TCP连接</h5>

<h5>1.2 T向B发送handshake packet</h5>

<h5>1.3 B向T回复handshake packet response</h5>

<h5>1.4 T向B发送ok packet</h5>

<p>在Replication Phase, 有以下步骤</p>

<h5>2.1 B向T查询<code>SELECT UNIX_TIMESTAMP()</code></h5>

<h5>2.2 B向T查询<code>SHOW VARIABLES LIKE 'SERVER_ID'</code></h5>

<h5>2.3 B向T执行<code>SET @master_heartbeat_period=</code></h5>

<h5>2.4 B向T发送COM_REGISTER_SLAVE packet, 得到T回复的ok packet</h5>

<h5>2.5 B向T发送COM_BINLOG_DUMP packet, T开始向B逐一发送binlog event packet</h5>

<p>到目前为止, 所有的packet定义都可以在<a href="http://dev.mysql.com/doc/internals/en/client-server-protocol.html">mysql internals</a>, 逐一实现即可. 这里只简述一些处理packet时需要注意的细节.</p>

<h4>处理packet时需要注意的细节</h4>

<ul>
<li>所有的packet都会包装一个<a href="http://dev.mysql.com/doc/internals/en/mysql-packet.html">header</a>, 其中包括packet payload(不包括header)的大小, 和序号</li>
<li>对于序号的处理, 比如2.2中B向T查询<code>SHOW VARIABLES LIKE 'SERVER_ID'</code>, B向T发送的第一个包序号为0, T向B回复的几个包序号依次递增为1,2,3...</li>
<li>注意数据类型, 仅整数, mysql的协议里有<a href="http://dev.mysql.com/doc/internals/en/integer.html">定长整数</a>和变长整数(length encoded integer), 需要特别留意packet payload的类型描述</li>
<li>说明一下<a href="http://dev.mysql.com/doc/internals/en/com-query-response.html#packet-COM_QUERY_Response">query response packet</a>. 比如B向T做一个查询, T将通过query response packet来返回查询结果. 需要说明的是, 如果查询结果为空 (比如<code>SET @master_heartbeat_period= ?</code>的结果), 仅需返回<code>COM_QUERY_RESPONSE</code>, 后面不需要跟着空的column定义和row数据</li>
</ul>


<h4>对超大packet的支持</h4>

<p>当一个packet过大 (超过<code>1&lt;&lt;24-1</code>byte ~= 16 MB) 时, 传输需要对packet进行切割, 参看<a href="http://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html">这里</a></p>

<p>注意, 在A上生成binlog时, 是可以容纳大于16MB的packet的, 也就是原binlog里存在超大的event, 需要在传输时加以限制</p>

<p>切割packet没什么特别之处, 仅需要注意包格式, 一个20MB的event的传输packet格式举例为 (此处用<code>16MB</code>便于描述, 应为<code>1&lt;&lt;24-1</code>byte):</p>

<pre><code>packet 1
    4字节 packet header
    1字节 值为[00], 是binlog event的特征标志
    16MB-1字节 为第一段数据

packet 2
    4字节 packet header
    20MB-16MB+1字节 为第二段数据
</code></pre>

<p>需要注意的是之后的packet时不带有[00]特征位的. 而包的大小计算范围为<strong>除去前4字节</strong>的全部字节</p>

<h4>一些资料</h4>

<p>除上文提到的资料, 还推荐<a href="http://boytnt.blog.51cto.com/966121/1279318">MySQL通讯协议研究系列</a>, 会对包格式有个直观感觉</p>

<h4>Trouble shooting</h4>

<p>在整个过程中, 有时候需要<code>gdb</code>到<code>mysqld</code>里来了解通讯协议的工作机制, 这里记录几个常用的函数入口点</p>

<h5>1. slave连接到master时</h5>

<pre><code>#0  wait_for_data (fd=21, timeout=3600) at /vagrant/mysql-5.5.35/sql-common/client.c:208
#1  0x00000000007316aa in my_connect (fd=21, name=0x7fa074004fd0, namelen=16, timeout=3600) at /vagrant/mysql-5.5.35/sql-common/client.c:187
#2  0x00000000007363cb in mysql_real_connect (mysql=0x7fa074004960, host=0x3959cc8 "192.168.56.1", user=0x3959d05 "repl", passwd=0x3959d36 "", db=0x0, port=3306, unix_socket=0x0, client_flag=2147483648)
    at /vagrant/mysql-5.5.35/sql-common/client.c:3282
#3  0x000000000057f138 in connect_to_master (thd=0x7fa074000a40, mysql=0x7fa074004960, mi=0x3959640, reconnect=false, suppress_warnings=false) at /vagrant/mysql-5.5.35/sql/slave.cc:4297
#4  0x000000000057edd1 in safe_connect (thd=0x7fa074000a40, mysql=0x7fa074004960, mi=0x3959640) at /vagrant/mysql-5.5.35/sql/slave.cc:4233
#5  0x000000000057b15c in handle_slave_io (arg=0x3959640) at /vagrant/mysql-5.5.35/sql/slave.cc:2851
#6  0x00007fa096751851 in start_thread () from /lib64/libpthread.so.0
#7  0x00007fa0954a690d in clone () from /lib64/libc.so.6
</code></pre>

<h5>2. handshake phase</h5>

<pre><code>#0  send_server_handshake_packet (mpvio=0x7fa0942eb450, data=0x391e5b4 "=!-\\gq$\\%&gt;J8z}'EgVW5", data_len=21) at /vagrant/mysql-5.5.35/sql/sql_acl.cc:8084
#1  0x000000000059a87c in server_mpvio_write_packet (param=0x7fa0942eb450, packet=0x391e5b4 "=!-\\gq$\\%&gt;J8z}'EgVW5", packet_len=21) at /vagrant/mysql-5.5.35/sql/sql_acl.cc:9082
#2  0x000000000059bc99 in native_password_authenticate (vio=0x7fa0942eb450, info=0x7fa0942eb468) at /vagrant/mysql-5.5.35/sql/sql_acl.cc:9713
#3  0x000000000059ad86 in do_auth_once (thd=0x391cc70, auth_plugin_name=0x1026760, mpvio=0x7fa0942eb450) at /vagrant/mysql-5.5.35/sql/sql_acl.cc:9336
#4  0x000000000059b23a in acl_authenticate (thd=0x391cc70, connect_errors=0, com_change_user_pkt_len=0) at /vagrant/mysql-5.5.35/sql/sql_acl.cc:9472
#5  0x00000000006d9eb5 in check_connection (thd=0x391cc70) at /vagrant/mysql-5.5.35/sql/sql_connect.cc:575
#6  0x00000000006d9ffc in login_connection (thd=0x391cc70) at /vagrant/mysql-5.5.35/sql/sql_connect.cc:633
#7  0x00000000006da5ba in thd_prepare_connection (thd=0x391cc70) at /vagrant/mysql-5.5.35/sql/sql_connect.cc:789
#8  0x00000000006daa28 in do_handle_one_connection (thd_arg=0x391cc70) at /vagrant/mysql-5.5.35/sql/sql_connect.cc:855
#9  0x00000000006da583 in handle_one_connection (arg=0x391cc70) at /vagrant/mysql-5.5.35/sql/sql_connect.cc:781
#10 0x00007fa096751851 in start_thread () from /lib64/libpthread.so.0
#11 0x00007fa0954a690d in clone () from /lib64/libc.so.6
</code></pre>

<h5>3. query时回复column定义</h5>

<pre><code>#0  Protocol::send_result_set_metadata (this=0x3767610, list=0x3769328, flags=5)
    at /vagrant/mysql-5.5.35/sql/protocol.cc:677
#1  0x00000000005c6745 in select_send::send_result_set_metadata (this=0x7f350c001658, list=..., flags=5)
    at /vagrant/mysql-5.5.35/sql/sql_class.cc:2132
#2  0x000000000062895a in JOIN::exec (this=0x7f350c001678) at /vagrant/mysql-5.5.35/sql/sql_select.cc:1858
#3  0x000000000062b2a0 in mysql_select (thd=0x37670e0, rref_pointer_array=0x3769400, tables=0x0, wild_num=0,
    fields=..., conds=0x0, og_num=0, order=0x0, group=0x0, having=0x0, proc_param=0x0, select_options=2147748608,
    result=0x7f350c001658, unit=0x3768bf8, select_lex=0x3769218) at /vagrant/mysql-5.5.35/sql/sql_select.cc:2604
#4  0x00000000006232f5 in handle_select (thd=0x37670e0, lex=0x3768b48, result=0x7f350c001658,
    setup_tables_done_option=0) at /vagrant/mysql-5.5.35/sql/sql_select.cc:297
#5  0x00000000005fe82d in execute_sqlcom_select (thd=0x37670e0, all_tables=0x0)
    at /vagrant/mysql-5.5.35/sql/sql_parse.cc:4627
#6  0x00000000005f7379 in mysql_execute_command (thd=0x37670e0) at /vagrant/mysql-5.5.35/sql/sql_parse.cc:2178
#7  0x0000000000600a43 in mysql_parse (thd=0x37670e0, rawbuf=0x7f350c001430 "SELECT UNIX_TIMESTAMP()", length=23,
    parser_state=0x7f35195056f0) at /vagrant/mysql-5.5.35/sql/sql_parse.cc:5664
#8  0x00000000005f490a in dispatch_command (command=COM_QUERY, thd=0x37670e0,
    packet=0x3770e21 "SELECT UNIX_TIMESTAMP()", packet_length=23) at /vagrant/mysql-5.5.35/sql/sql_parse.cc:1040
#9  0x00000000005f3c00 in do_command (thd=0x37670e0) at /vagrant/mysql-5.5.35/sql/sql_parse.cc:773
#10 0x00000000006daa4b in do_handle_one_connection (thd_arg=0x37670e0)
    at /vagrant/mysql-5.5.35/sql/sql_connect.cc:862
#11 0x00000000006da583 in handle_one_connection (arg=0x37670e0) at /vagrant/mysql-5.5.35/sql/sql_connect.cc:781
#12 0x00007f352e043851 in start_thread () from /lib64/libpthread.so.0
#13 0x00007f352cd9890d in clone () from /lib64/libc.so.6
</code></pre>

<h5>4. query读取数据结果</h5>

<pre><code>#0  cli_read_query_result (mysql=0x7f3508004960) at /vagrant/mysql-5.5.35/sql-common/client.c:3829
#1  0x0000000000738016 in mysql_real_query (mysql=0x7f3508004960, query=0xb80e34 "SELECT UNIX_TIMESTAMP()",
    length=23) at /vagrant/mysql-5.5.35/sql-common/client.c:3918
#2  0x00000000005766ec in get_master_version_and_clock (mysql=0x7f3508004960, mi=0x375b400)
    at /vagrant/mysql-5.5.35/sql/slave.cc:1328
#3  0x000000000057b35a in handle_slave_io (arg=0x375b400) at /vagrant/mysql-5.5.35/sql/slave.cc:2881
#4  0x00007f352e043851 in start_thread () from /lib64/libpthread.so.0
#5  0x00007f352cd9890d in clone () from /lib64/libc.so.6
</code></pre>

<h5>5. slave发送COM_BINLOG_DUMP</h5>

<pre><code>#0  request_dump (thd=0x7f35f80008c0, mysql=0x7f35f80076c0, mi=0x3301ac0,
    suppress_warnings=0x7f361c189e2b)
    at /vagrant/mysql-5.5.35/sql/slave.cc:2184
#1  0x000000000057b596 in handle_slave_io (arg=0x3301ac0)
    at /vagrant/mysql-5.5.35/sql/slave.cc:2935
#2  0x00007f3620c66851 in start_thread () from /lib64/libpthread.so.0
#3  0x00007f361f9bb90d in clone () from /lib64/libc.so.6
</code></pre>
]]></content>
  </entry>
  
</feed>
