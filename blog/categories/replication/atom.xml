<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: replication | Tac say]]></title>
  <link href="http://ikarishinjieva.github.com/blog/blog/categories/replication/atom.xml" rel="self"/>
  <link href="http://ikarishinjieva.github.com/blog/"/>
  <updated>2014-04-11T00:55:59+08:00</updated>
  <id>http://ikarishinjieva.github.com/blog/</id>
  <author>
    <name><![CDATA[Tac Huang (ikari_shinji@github)]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[对Mysql bug #70307 的再学习]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2014/04/01/study-mysql-bug-70307-2/"/>
    <updated>2014-04-01T13:07:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2014/04/01/study-mysql-bug-70307-2</id>
    <content type="html"><![CDATA[<p>之前对bug #70307有过<a href="http://ikarishinjieva.github.io/blog/blog/2013/10/25/study-mysql-bug-70307/">学习</a>, 苦于阿兹海默状态, 又花了半天在mysql 5.5.33上探查这个场景的原因...</p>

<p>简单记录一下</p>

<h4>现象</h4>

<p>mysql进行主从复制, 从机上<code>FLUSH TABLES WITH READ LOCK</code>后, 进行<code>STOP SLAVE</code>, 一定概率下 <code>SHOW SLAVE STATUS</code>卡住</p>

<h4>重现步骤</h4>

<table>
<thead>
<tr>
<th>master </th>
<th> slave client 1 </th>
<th> slave client 2</th>
</tr>
</thead>
<tbody>
<tr>
<td> - </td>
<td> STOP SLAVE IO_THREAD </td>
<td> -</td>
</tr>
<tr>
<td> CREATE TABLE TEST.TEST ... </td>
<td> - </td>
<td> -</td>
</tr>
<tr>
<td> - </td>
<td> FLUSH TABLES WITH READ LOCK </td>
<td> -</td>
</tr>
<tr>
<td> - </td>
<td> START SLAVE IO_THREAD </td>
<td> -</td>
</tr>
<tr>
<td> - </td>
<td> - </td>
<td> STOP SLAVE</td>
</tr>
<tr>
<td> - </td>
<td> SHOW SLAVE STATUS </td>
<td> -</td>
</tr>
</tbody>
</table>


<p>其中, <code>START/STOP SLAVE IO_THREAD</code>是为了在<code>FLUSH TABLES WITH READ LOCK</code>时造成slave io_thread有未提交数据</p>

<h4>死锁原因</h4>

<ol>
<li><code>FLUSH TABLES WITH READ LOCK</code> 会阻塞IO_THREAD提交数据</li>
<li><code>STOP SLAVE</code>会等待IO_THREAD结束 (<code>mi-&gt;stop_cond</code>), 即<code>STOP SLAVE</code>间接被<code>FLUSH TABLES WITH READ LOCK</code>阻塞</li>
<li><code>STOP SLAVE</code>在被阻塞前, 持有了<code>LOCK_active_mi</code>, 独占了<code>master_info</code></li>
<li><code>SHOW SLAVE STATUS</code>会申请锁<code>LOCK_active_mi</code>, 被<code>STOP SLAVE</code>阻塞</li>
<li>如果<code>SHOW SLAVE STATUS</code>是由之前<code>FLUSH TABLES WITH READ LOCK</code>的<code>slave client 1</code>发出的, 那逻辑上相当于自己在等待自己释放资源</li>
<li>从另外的client上<code>UNLOCK TABLES</code>也解不开</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[mysql, 利用假master重放binlog]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2014/03/26/mysql-fake-master-server/"/>
    <updated>2014-03-26T20:08:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2014/03/26/mysql-fake-master-server</id>
    <content type="html"><![CDATA[<h4>场景</h4>

<p>这次想解决的场景是想在一个mysqld实例上重放一些来自于其他实例的binlog, 传统的方法是<code>mysqlbinlog</code>. 但是<code>mysqlbinlog</code>会带来一些问题, 比如这个<a href="http://bugs.mysql.com/bug.php?id=33048">bug</a></p>

<p>后同事转给我一种利用<a href="http://www.orczhou.com/index.php/2013/11/use-mysql-replication-to-recove-binlog/">复制重放binlog的方法</a>, 其中提到两种方式:</p>

<ul>
<li>第一种是修改relay log的信息, 将binlog作为relay log来放. 这是种很好的方法, 缺点是<code>mysqld</code>需要停机重启. 如果不重启, server中对于<code>relay-log.index</code>和<code>relay-log.info</code>等的缓存不会刷新.</li>
<li>第二种是起另外一个mysqld实例, 将binlog作为relay log, 再将此实例作为master, 向目标实例进行复制. 这种方式的缺点是作为中间人的mysqld实例需要消耗资源</li>
</ul>


<p>于是想办法将第二种方法进行改进, 即制造一个假的master, 实现简单的复制协议, 直接将binlog复制给目标mysqld实例. 与第二种方式相比, 好处在于只使用少量资源 (一个端口, 一点用来读文件的内存).</p>

<h4>实现</h4>

<p>实现参看我的<a href="https://github.com/ikarishinjieva/mysql_binlog_utils/blob/master/fake_master_server.go">github</a></p>

<p><strong>注意: 此实现仅适用于mysql 5.5.33, 其它版本未测试</strong></p>

<p>由于<a href="http://dev.mysql.com/doc/internals/en/client-server-protocol.html">mysql internals</a> 已经将mysql的网络协议写的比较详细, 需要做的只是起一个tcp的server, 同目标mysqld实例进行交互即可.</p>

<p>此处逐层介绍实现, 将忽略不需要特别注意的部分. 为了简单, 将binlog的来源mysqld实例称为A, 目标mysqld实例称为B, 假master称为T.</p>

<p>目标就是讲从A获得的binlog文件, 通过T, 在B上重放出来</p>

<p>从B发起<code>start slave</code>, 到T真正向B复制数据, 需要下面两个阶段</p>

<h5>1. Handshake Phase</h5>

<h5>2. Replication Phase</h5>

<p>先介绍Handshake Phase, 有以下步骤</p>

<h5>1.1 B执行<code>start slave</code>, 此时B向T建立一个TCP连接</h5>

<h5>1.2 T向B发送handshake packet</h5>

<h5>1.3 B向T回复handshake packet response</h5>

<h5>1.4 T向B发送ok packet</h5>

<p>在Replication Phase, 有以下步骤</p>

<h5>2.1 B向T查询<code>SELECT UNIX_TIMESTAMP()</code></h5>

<h5>2.2 B向T查询<code>SHOW VARIABLES LIKE 'SERVER_ID'</code></h5>

<h5>2.3 B向T执行<code>SET @master_heartbeat_period=</code></h5>

<h5>2.4 B向T发送COM_REGISTER_SLAVE packet, 得到T回复的ok packet</h5>

<h5>2.5 B向T发送COM_BINLOG_DUMP packet, T开始向B逐一发送binlog event packet</h5>

<p>到目前为止, 所有的packet定义都可以在<a href="http://dev.mysql.com/doc/internals/en/client-server-protocol.html">mysql internals</a>, 逐一实现即可. 这里只简述一些处理packet时需要注意的细节.</p>

<h4>处理packet时需要注意的细节</h4>

<ul>
<li>所有的packet都会包装一个<a href="http://dev.mysql.com/doc/internals/en/mysql-packet.html">header</a>, 其中包括packet payload(不包括header)的大小, 和序号</li>
<li>对于序号的处理, 比如2.2中B向T查询<code>SHOW VARIABLES LIKE 'SERVER_ID'</code>, B向T发送的第一个包序号为0, T向B回复的几个包序号依次递增为1,2,3...</li>
<li>注意数据类型, 仅整数, mysql的协议里有<a href="http://dev.mysql.com/doc/internals/en/integer.html">定长整数</a>和变长整数(length encoded integer), 需要特别留意packet payload的类型描述</li>
<li>说明一下<a href="http://dev.mysql.com/doc/internals/en/com-query-response.html#packet-COM_QUERY_Response">query response packet</a>. 比如B向T做一个查询, T将通过query response packet来返回查询结果. 需要说明的是, 如果查询结果为空 (比如<code>SET @master_heartbeat_period= ?</code>的结果), 仅需返回<code>COM_QUERY_RESPONSE</code>, 后面不需要跟着空的column定义和row数据</li>
</ul>


<h4>对超大packet的支持</h4>

<p>当一个packet过大 (超过<code>1&lt;&lt;24-1</code>byte ~= 16 MB) 时, 传输需要对packet进行切割, 参看<a href="http://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html">这里</a></p>

<p>注意, 在A上生成binlog时, 是可以容纳大于16MB的packet的, 也就是原binlog里存在超大的event, 需要在传输时加以限制</p>

<p>切割packet没什么特别之处, 仅需要注意包格式, 一个20MB的event的传输packet格式举例为 (此处用<code>16MB</code>便于描述, 应为<code>1&lt;&lt;24-1</code>byte):</p>

<pre><code>packet 1
    4字节 packet header
    1字节 值为[00], 是binlog event的特征标志
    16MB-1字节 为第一段数据

packet 2
    4字节 packet header
    20MB-16MB+1字节 为第二段数据
</code></pre>

<p>需要注意的是之后的packet时不带有[00]特征位的. 而包的大小计算范围为<strong>除去前4字节</strong>的全部字节</p>

<h4>一些资料</h4>

<p>除上文提到的资料, 还推荐<a href="http://boytnt.blog.51cto.com/966121/1279318">MySQL通讯协议研究系列</a>, 会对包格式有个直观感觉</p>

<h4>Trouble shooting</h4>

<p>在整个过程中, 有时候需要<code>gdb</code>到<code>mysqld</code>里来了解通讯协议的工作机制, 这里记录几个常用的函数入口点</p>

<h5>1. slave连接到master时</h5>

<pre><code>#0  wait_for_data (fd=21, timeout=3600) at /vagrant/mysql-5.5.35/sql-common/client.c:208
#1  0x00000000007316aa in my_connect (fd=21, name=0x7fa074004fd0, namelen=16, timeout=3600) at /vagrant/mysql-5.5.35/sql-common/client.c:187
#2  0x00000000007363cb in mysql_real_connect (mysql=0x7fa074004960, host=0x3959cc8 "192.168.56.1", user=0x3959d05 "repl", passwd=0x3959d36 "", db=0x0, port=3306, unix_socket=0x0, client_flag=2147483648)
    at /vagrant/mysql-5.5.35/sql-common/client.c:3282
#3  0x000000000057f138 in connect_to_master (thd=0x7fa074000a40, mysql=0x7fa074004960, mi=0x3959640, reconnect=false, suppress_warnings=false) at /vagrant/mysql-5.5.35/sql/slave.cc:4297
#4  0x000000000057edd1 in safe_connect (thd=0x7fa074000a40, mysql=0x7fa074004960, mi=0x3959640) at /vagrant/mysql-5.5.35/sql/slave.cc:4233
#5  0x000000000057b15c in handle_slave_io (arg=0x3959640) at /vagrant/mysql-5.5.35/sql/slave.cc:2851
#6  0x00007fa096751851 in start_thread () from /lib64/libpthread.so.0
#7  0x00007fa0954a690d in clone () from /lib64/libc.so.6
</code></pre>

<h5>2. handshake phase</h5>

<pre><code>#0  send_server_handshake_packet (mpvio=0x7fa0942eb450, data=0x391e5b4 "=!-\\gq$\\%&gt;J8z}'EgVW5", data_len=21) at /vagrant/mysql-5.5.35/sql/sql_acl.cc:8084
#1  0x000000000059a87c in server_mpvio_write_packet (param=0x7fa0942eb450, packet=0x391e5b4 "=!-\\gq$\\%&gt;J8z}'EgVW5", packet_len=21) at /vagrant/mysql-5.5.35/sql/sql_acl.cc:9082
#2  0x000000000059bc99 in native_password_authenticate (vio=0x7fa0942eb450, info=0x7fa0942eb468) at /vagrant/mysql-5.5.35/sql/sql_acl.cc:9713
#3  0x000000000059ad86 in do_auth_once (thd=0x391cc70, auth_plugin_name=0x1026760, mpvio=0x7fa0942eb450) at /vagrant/mysql-5.5.35/sql/sql_acl.cc:9336
#4  0x000000000059b23a in acl_authenticate (thd=0x391cc70, connect_errors=0, com_change_user_pkt_len=0) at /vagrant/mysql-5.5.35/sql/sql_acl.cc:9472
#5  0x00000000006d9eb5 in check_connection (thd=0x391cc70) at /vagrant/mysql-5.5.35/sql/sql_connect.cc:575
#6  0x00000000006d9ffc in login_connection (thd=0x391cc70) at /vagrant/mysql-5.5.35/sql/sql_connect.cc:633
#7  0x00000000006da5ba in thd_prepare_connection (thd=0x391cc70) at /vagrant/mysql-5.5.35/sql/sql_connect.cc:789
#8  0x00000000006daa28 in do_handle_one_connection (thd_arg=0x391cc70) at /vagrant/mysql-5.5.35/sql/sql_connect.cc:855
#9  0x00000000006da583 in handle_one_connection (arg=0x391cc70) at /vagrant/mysql-5.5.35/sql/sql_connect.cc:781
#10 0x00007fa096751851 in start_thread () from /lib64/libpthread.so.0
#11 0x00007fa0954a690d in clone () from /lib64/libc.so.6
</code></pre>

<h5>3. query时回复column定义</h5>

<pre><code>#0  Protocol::send_result_set_metadata (this=0x3767610, list=0x3769328, flags=5)
    at /vagrant/mysql-5.5.35/sql/protocol.cc:677
#1  0x00000000005c6745 in select_send::send_result_set_metadata (this=0x7f350c001658, list=..., flags=5)
    at /vagrant/mysql-5.5.35/sql/sql_class.cc:2132
#2  0x000000000062895a in JOIN::exec (this=0x7f350c001678) at /vagrant/mysql-5.5.35/sql/sql_select.cc:1858
#3  0x000000000062b2a0 in mysql_select (thd=0x37670e0, rref_pointer_array=0x3769400, tables=0x0, wild_num=0,
    fields=..., conds=0x0, og_num=0, order=0x0, group=0x0, having=0x0, proc_param=0x0, select_options=2147748608,
    result=0x7f350c001658, unit=0x3768bf8, select_lex=0x3769218) at /vagrant/mysql-5.5.35/sql/sql_select.cc:2604
#4  0x00000000006232f5 in handle_select (thd=0x37670e0, lex=0x3768b48, result=0x7f350c001658,
    setup_tables_done_option=0) at /vagrant/mysql-5.5.35/sql/sql_select.cc:297
#5  0x00000000005fe82d in execute_sqlcom_select (thd=0x37670e0, all_tables=0x0)
    at /vagrant/mysql-5.5.35/sql/sql_parse.cc:4627
#6  0x00000000005f7379 in mysql_execute_command (thd=0x37670e0) at /vagrant/mysql-5.5.35/sql/sql_parse.cc:2178
#7  0x0000000000600a43 in mysql_parse (thd=0x37670e0, rawbuf=0x7f350c001430 "SELECT UNIX_TIMESTAMP()", length=23,
    parser_state=0x7f35195056f0) at /vagrant/mysql-5.5.35/sql/sql_parse.cc:5664
#8  0x00000000005f490a in dispatch_command (command=COM_QUERY, thd=0x37670e0,
    packet=0x3770e21 "SELECT UNIX_TIMESTAMP()", packet_length=23) at /vagrant/mysql-5.5.35/sql/sql_parse.cc:1040
#9  0x00000000005f3c00 in do_command (thd=0x37670e0) at /vagrant/mysql-5.5.35/sql/sql_parse.cc:773
#10 0x00000000006daa4b in do_handle_one_connection (thd_arg=0x37670e0)
    at /vagrant/mysql-5.5.35/sql/sql_connect.cc:862
#11 0x00000000006da583 in handle_one_connection (arg=0x37670e0) at /vagrant/mysql-5.5.35/sql/sql_connect.cc:781
#12 0x00007f352e043851 in start_thread () from /lib64/libpthread.so.0
#13 0x00007f352cd9890d in clone () from /lib64/libc.so.6
</code></pre>

<h5>4. query读取数据结果</h5>

<pre><code>#0  cli_read_query_result (mysql=0x7f3508004960) at /vagrant/mysql-5.5.35/sql-common/client.c:3829
#1  0x0000000000738016 in mysql_real_query (mysql=0x7f3508004960, query=0xb80e34 "SELECT UNIX_TIMESTAMP()",
    length=23) at /vagrant/mysql-5.5.35/sql-common/client.c:3918
#2  0x00000000005766ec in get_master_version_and_clock (mysql=0x7f3508004960, mi=0x375b400)
    at /vagrant/mysql-5.5.35/sql/slave.cc:1328
#3  0x000000000057b35a in handle_slave_io (arg=0x375b400) at /vagrant/mysql-5.5.35/sql/slave.cc:2881
#4  0x00007f352e043851 in start_thread () from /lib64/libpthread.so.0
#5  0x00007f352cd9890d in clone () from /lib64/libc.so.6
</code></pre>

<h5>5. slave发送COM_BINLOG_DUMP</h5>

<pre><code>#0  request_dump (thd=0x7f35f80008c0, mysql=0x7f35f80076c0, mi=0x3301ac0,
    suppress_warnings=0x7f361c189e2b)
    at /vagrant/mysql-5.5.35/sql/slave.cc:2184
#1  0x000000000057b596 in handle_slave_io (arg=0x3301ac0)
    at /vagrant/mysql-5.5.35/sql/slave.cc:2935
#2  0x00007f3620c66851 in start_thread () from /lib64/libpthread.so.0
#3  0x00007f361f9bb90d in clone () from /lib64/libc.so.6
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[尝试使用mysql plugin将RESET SLAVE后的节点重新恢复成slave]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2014/02/11/try-rollback-master-back-to-slave-by-mysql-plugin/"/>
    <updated>2014-02-11T22:31:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2014/02/11/try-rollback-master-back-to-slave-by-mysql-plugin</id>
    <content type="html"><![CDATA[<p>这几天在尝试为以下场景制作一个mysql plugin, 但是是一个失败的尝试, 在此记录</p>

<pre><code>一对mysql主从节点 M-S, 节点S执行了RESET SLAVE
后来后悔了
在没有数据通过非replication的渠道写入S的条件下, 想让S和M重新恢复成一对主从
</code></pre>

<p>关键点是S能将<code>RESET SLAVE</code>时S的<code>Exec_Master_Log_Pos</code>和<code>S binlog pos</code>记录下来</p>

<p>尝试了以下几种方案:</p>

<h5>1. 调用者在<code>RESET SLAVE</code>时手工记录, 不需要制作插件</h5>

<hr />

<h5>2. Audit plugin.</h5>

<p>Mysql的Audit plugin可以审计大部分mysqld经手的SQL, 包括<code>RESET SLAVE</code>.</p>

<p>但Audit plugin是在每个SQL之后才会调用. 在<code>RESET SLAVE</code>时S上master_info会被清理, 即<code>Exec_Master_Log_Pos</code>的信息在调用Audit plugin已经丢失</p>

<hr />

<h5>3. Replication plugin (<code>after_reset_slave</code>)</h5>

<p>Replication plugin (参看mysql semisync的源码), 在slave端提供了<code>Binlog_relay_IO_observer</code>, 贴个Mysql源码方便理解</p>

<pre><code>/**
    Observes and extends the service of slave IO thread.
 */
 typedef struct Binlog_relay_IO_observer {
   uint32 len;

   /**
      This callback is called when slave IO thread starts

      @param param Observer common parameter

      @retval 0 Sucess
      @retval 1 Failure
   */
   int (*thread_start)(Binlog_relay_IO_param *param);

   /**
      This callback is called when slave IO thread stops

      @param param Observer common parameter

      @retval 0 Sucess
      @retval 1 Failure
   */
   int (*thread_stop)(Binlog_relay_IO_param *param);

   /**
      This callback is called before slave requesting binlog transmission from master

      This is called before slave issuing BINLOG_DUMP command to master
      to request binlog.

      @param param Observer common parameter
      @param flags binlog dump flags

      @retval 0 Sucess
      @retval 1 Failure
   */
   int (*before_request_transmit)(Binlog_relay_IO_param *param, uint32 flags);

   /**
      This callback is called after read an event packet from master

      @param param Observer common parameter
      @param packet The event packet read from master
      @param len Length of the event packet read from master
      @param event_buf The event packet return after process
      @param event_len The length of event packet return after process

      @retval 0 Sucess
      @retval 1 Failure
   */
   int (*after_read_event)(Binlog_relay_IO_param *param,
                           const char *packet, unsigned long len,
                           const char **event_buf, unsigned long *event_len);

   /**
      This callback is called after written an event packet to relay log

      @param param Observer common parameter
      @param event_buf Event packet written to relay log
      @param event_len Length of the event packet written to relay log
      @param flags flags for relay log

      @retval 0 Sucess
      @retval 1 Failure
   */
   int (*after_queue_event)(Binlog_relay_IO_param *param,
                            const char *event_buf, unsigned long event_len,
                            uint32 flags);

   /**
      This callback is called after reset slave relay log IO status

      @param param Observer common parameter

      @retval 0 Sucess
      @retval 1 Failure
   */
   int (*after_reset_slave)(Binlog_relay_IO_param *param);
 } Binlog_relay_IO_observer;
</code></pre>

<p>首先尝试用<code>after_reset_slave</code>, 从函数名字就可以看到会遇到和Audit Plugin相同的问题: 即<code>Exec_Master_Log_Pos</code>的信息在调用时已经丢失</p>

<hr />

<h5>4. Replication plugin (<code>after_reset_slave</code>再尝试, <code>future_group_master_log_pos</code>)</h5>

<p>还不死心, <code>Exec_Master_Log_Pos</code>的数据结构是<code>Relay_log_info.group_master_log_pos</code>, 尽管这个信息在<code>after_reset_slave</code>时已经丢失, 但发现<code>Relay_log_info.future_group_master_log_pos</code>可能是个方向</p>

<p>先解释<code>Relay_log_info.future_group_master_log_pos</code>, 可以参看<code>log_event.cc</code>的这段注释</p>

<pre><code>  /*
    InnoDB internally stores the master log position it has executed so far,
    i.e. the position just after the COMMIT event.
    When InnoDB will want to store, the positions in rli won't have
    been updated yet, so group_master_log_* will point to old BEGIN
    and event_master_log* will point to the beginning of current COMMIT.
    But log_pos of the COMMIT Query event is what we want, i.e. the pos of the
    END of the current log event (COMMIT). We save it in rli so that InnoDB can
    access it.
  */
  const_cast&lt;Relay_log_info*&gt;(rli)-&gt;future_group_master_log_pos= log_pos;
</code></pre>

<p><code>future_group_master_log_pos</code>指向了execute的最后一个transaction的COMMIT event之前, 即<code>future_group_master_log_pos</code> 大部分时间等于 <code>group_master_log_pos - 27</code> (27是COMMIT event的长度)</p>

<p>但仍有例外情况: 如果M执行了<code>FLUSH LOGS</code>, 将log从0001递增到了0002, 此时S上的<code>future_group_master_log_pos</code>会指向0001的最后一个transaction的COMMIT event之前. 但S上的<code>group_master_log_name</code>已经到了0002, 与<code>future_group_master_log_pos</code>不匹配, 会引起异常</p>

<p>(其实此时S上的<code>group_master_log_name</code>也已经置空了, 但可以从内存残片中恢复出文件名)</p>

<p>设想如果对于log_name也有<code>future_group_master_log_name</code>, 那么S可以直接<code>change master</code>到M的<code>future_group_master_log_name</code>和<code>future_group_master_log_pos</code>位置, 可以恢复起M-S主从结构</p>

<hr />

<h5>5. Replication plugin (<code>thread_stop</code>)</h5>

<p>Replication plugin的<code>thread_stop</code>是指Slave IO thread停止时调用, 此时可以拿到<code>Exec_Master_Log_Pos</code>和<code>S binlog pos</code>, 但拿到的<code>S binlog pos</code>没有意义, 因为不能保证Slave SQL thread也停下来了</p>

<hr />

<h5>6. Storage Engine plugin</h5>

<p>这是我最后一根救命稻草, 阅读Mysql源码时注意到以下片段(做了缩减)</p>

<pre><code>int reset_slave(THD *thd, Master_info* mi)
{
    ...
    ha_reset_slave(thd);
    ... //clean memory data
}
</code></pre>

<p><code>reset_slave</code>在清理内存数据前通知了storage engine插件, 这个插件可以获得所有必要信息</p>

<p>但存在一个问题, 即<code>ha_reset_slave</code>仅在Mysql NDB版本中存在, 不具备通用性, 参看宏定义(做了缩减)</p>

<pre><code>#ifdef HAVE_NDB_BINLOG
...
void ha_reset_slave(THD *thd);
...
#else
...
#define ha_reset_slave(a) do {} while (0)
...
#endif
</code></pre>

<hr />

<h4>吐槽和总结</h4>

<p>可以看到Mysql plugin不<strong>太</strong>预留接口, 是仅仅为已知应用场景提供必要接口, 比如<code>Binlog_relay_IO_observer</code>中有<code>after</code>不一定有<code>before</code>. 比较容易控制插件质量, 但插件能做到的非常局限.</p>

<p>以上各种尝试, 归根到底, 只要修改Mysql的一点源码编译一下就可以达到很好的效果, 不需要用插件的方式在Mysql中到处找功能插槽, 但通用性变差.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[对Mysql bug #70307 的学习]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2013/10/25/study-mysql-bug-70307/"/>
    <updated>2013-10-25T22:00:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2013/10/25/study-mysql-bug-70307</id>
    <content type="html"><![CDATA[<p>之前描述<a href="http://ikarishinjieva.github.io/blog/blog/2013/10/11/hole-in-mysql-56-replication-dead-lock/">Mysql 5.6.15 Replication中碰到的死锁</a>的情况，这次尝试debug下原因。</p>

<h2>debug的过程</h2>

<p>用参数--gdb启动mysql，按照<a href="http://bugs.mysql.com/file.php?id=20542">步骤</a>重现bug（让slave "show slave status"时卡住）。然后用gdb attach到slave mysql实例上。</p>

<pre><code>(gdb) thread apply all bt
</code></pre>

<p>输出所有线程的backtrace，找到show slave status卡住的线程和位置</p>

<pre><code>Thread 2 (Thread 0x7f583c166700 (LWP 2440)):
#0  0x00007f583f484054 in __lll_lock_wait () from /lib64/libpthread.so.0
#1  0x00007f583f47f3be in _L_lock_995 () from /lib64/libpthread.so.0
#2  0x00007f583f47f326 in pthread_mutex_lock () from /lib64/libpthread.so.0
#3  0x0000000000aa3cde in safe_mutex_lock (mp=0x3516ae8, try_lock=0 '\000', file=0xfb8e58 "/home/vagrant/mysql-5.6.12/sql/rpl_slave.cc", line=2611) at /home/vagrant/mysql-5.6.12/mysys/thr_mutex.c:152
#4  0x0000000000a4b993 in inline_mysql_mutex_lock (that=0x3516ae8, src_file=0xfb8e58 "/home/vagrant/mysql-5.6.12/sql/rpl_slave.cc", src_line=2611) at /home/vagrant/mysql-5.6.12/include/mysql/psi/mysql_thread.h:686
#5  0x0000000000a53cb3 in show_slave_status (thd=0x352e3d0, mi=0x34b4f20) at /home/vagrant/mysql-5.6.12/sql/rpl_slave.cc:2611
#6  0x00000000007d45f4 in mysql_execute_command (thd=0x352e3d0) at /home/vagrant/mysql-5.6.12/sql/sql_parse.cc:2766
#7  0x00000000007ddc46 in mysql_parse (thd=0x352e3d0, rawbuf=0x7f57ec005010 "show slave status", length=17, parser_state=0x7f583c165660) at /home/vagrant/mysql-5.6.12/sql/sql_parse.cc:6187
#8  0x00000000007d1019 in dispatch_command (command=COM_QUERY, thd=0x352e3d0, packet=0x3534e51 "", packet_length=17) at /home/vagrant/mysql-5.6.12/sql/sql_parse.cc:1334
#9  0x00000000007d017b in do_command (thd=0x352e3d0) at /home/vagrant/mysql-5.6.12/sql/sql_parse.cc:1036
#10 0x0000000000797a08 in do_handle_one_connection (thd_arg=0x352e3d0) at /home/vagrant/mysql-5.6.12/sql/sql_connect.cc:977
#11 0x00000000007974e4 in handle_one_connection (arg=0x352e3d0) at /home/vagrant/mysql-5.6.12/sql/sql_connect.cc:893
#12 0x0000000000aea87a in pfs_spawn_thread (arg=0x351b510) at /home/vagrant/mysql-5.6.12/storage/perfschema/pfs.cc:1855
#13 0x00007f583f47d851 in start_thread () from /lib64/libpthread.so.0
#14 0x00007f583e3e890d in clone () from /lib64/libc.so.6
</code></pre>

<p>可以看到show slave status卡在</p>

<pre><code>#5  0x0000000000a53cb3 in show_slave_status (thd=0x352e3d0, mi=0x34b4f20) at /home/vagrant/mysql-5.6.12/sql/rpl_slave.cc:2611
</code></pre>

<p>查找源码可以看到show slave status卡在获取锁mi->rli->data_lock上<br/>(科普下缩写: mi=master info, rli=relay log info</p>

<p>在gdb中运行命令</p>

<pre><code>(gdb) thread 2
(gdb) f 5
(gdb) print mi-&gt;rli-&gt;data_lock
</code></pre>

<p>切换到thread 2堆栈第5层的上下文，打印出mi->rli->data_lock变量，输出如下</p>

<pre><code>$1 = {m_mutex = {global = {__data = {__lock = 0, __count = 0, __owner = 0, __nusers = 0, __kind = 2, __spins = 0,
    __list = {__prev = 0x0, __next = 0x0}},
  __size = '\000' &lt;repeats 16 times&gt;, "\002", '\000' &lt;repeats 22 times&gt;, __align = 0}, mutex = {__data = {
    __lock = 2, __count = 0, __owner = 2435, __nusers = 1, __kind = 3, __spins = 0, __list = {__prev = 0x0,
      __next = 0x0}},
  __size = "\002\000\000\000\000\000\000\000\203\t\000\000\001\000\000\000\003", '\000' &lt;repeats 22 times&gt;,
  __align = 2}, file = 0xfa4520 "/home/vagrant/mysql-5.6.12/sql/log_event.cc", line = 7259, count = 1,
thread = 140016942216960}, m_psi = 0x0}
</code></pre>

<p>看到锁的owner是线程(LWP 2435)，为Thread 3</p>

<p>Thread 3的backtrace如下</p>

<pre><code>Thread 3 (Thread 0x7f583c1a7700 (LWP 2435)):
#0  0x00007f583f4817bb in pthread_cond_timedwait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0
#1  0x0000000000aa429d in safe_cond_timedwait (cond=0x7f57f4000ba8, mp=0x7f57f4000b38, abstime=0x7f583c1a60f0, file=0xedc960 "/home/vagrant/mysql-5.6.12/include/mysql/psi/mysql_thread.h", line=1199) at /home/vagrant/mysql-5.6.12/mysys/thr_mutex.c:278
#2  0x00000000007121f4 in inline_mysql_cond_timedwait (that=0x7f57f4000ba8, mutex=0x7f57f4000b38, abstime=0x7f583c1a60f0, src_file=0xedcb98 "/home/vagrant/mysql-5.6.12/sql/mdl.cc", src_line=1306) at /home/vagrant/mysql-5.6.12/include/mysql/psi/mysql_thread.h:1199
#3  0x0000000000713111 in MDL_wait::timed_wait (this=0x7f57f4000b38, owner=0x7f57f4000a50, abs_timeout=0x7f583c1a60f0, set_status_on_timeout=true, wait_state_name=0x14d0488) at /home/vagrant/mysql-5.6.12/sql/mdl.cc:1306
#4  0x0000000000714811 in MDL_context::acquire_lock (this=0x7f57f4000b38, mdl_request=0x7f583c1a6180, lock_wait_timeout=31536000) at /home/vagrant/mysql-5.6.12/sql/mdl.cc:2241
#5  0x000000000063656a in ha_commit_trans (thd=0x7f57f4000a50, all=true) at /home/vagrant/mysql-5.6.12/sql/handler.cc:1396 (COMMIT LOCK)
#6  0x00000000008a010b in trans_commit (thd=0x7f57f4000a50) at /home/vagrant/mysql-5.6.12/sql/transaction.cc:228
#7  0x0000000000a081bb in Xid_log_event::do_commit (this=0x7f57f4004730, thd=0x7f57f4000a50) at /home/vagrant/mysql-5.6.12/sql/log_event.cc:7174
#8  0x0000000000a0886e in Xid_log_event::do_apply_event (this=0x7f57f4004730, rli=0x3516650) at /home/vagrant/mysql-5.6.12/sql/log_event.cc:7310 (rli-&gt;data_lock)
#9  0x00000000009fd956 in Log_event::apply_event (this=0x7f57f4004730, rli=0x3516650) at /home/vagrant/mysql-5.6.12/sql/log_event.cc:3049
#10 0x0000000000a55e31 in apply_event_and_update_pos (ptr_ev=0x7f583c1a68a0, thd=0x7f57f4000a50, rli=0x3516650) at /home/vagrant/mysql-5.6.12/sql/rpl_slave.cc:3374
#11 0x0000000000a56e45 in exec_relay_log_event (thd=0x7f57f4000a50, rli=0x3516650) at /home/vagrant/mysql-5.6.12/sql/rpl_slave.cc:3742
#12 0x0000000000a5c334 in handle_slave_sql (arg=0x34b4f20) at /home/vagrant/mysql-5.6.12/sql/rpl_slave.cc:5552
#13 0x0000000000aea87a in pfs_spawn_thread (arg=0x350a800) at /home/vagrant/mysql-5.6.12/storage/perfschema/pfs.cc:1855
#14 0x00007f583f47d851 in start_thread () from /lib64/libpthread.so.0
#15 0x00007f583e3e890d in clone () from /lib64/libc.so.6
</code></pre>

<p>可以看到Thread 3卡在commit lock上，同时查源码看到Thread 3同时占有了rli->data_lock (log_event.cc:7259)</p>

<h2>锁的状态</h2>

<p>按照bug的描述，</p>

<ol>
<li>flush tables with read lock; 会持有commit lock</li>
<li>IO thread (Thread 3)会持有rli->data_lock，并等待commit lock</li>
<li>show slave status; 会等待rli->data_lock</li>
</ol>


<p>结果导致show slave status卡住不可用</p>

<h2>臆测一下解决方法</h2>

<p>鉴于功底不深，只能臆测一下</p>

<ol>
<li>IO thread持有锁rli->data_lock的原因是要更新relay log的状态，然后进行commit(Xid_log_event::do_apply_event (log_event.cc:7248))。在commit的时候不会更新rli的数据。</li>
<li>show slave status不会更新rli的数据，需要锁rli->data_lock的原因是要一致性数据。</li>
</ol>


<p>因此可能的解决方案是IO thread持有读写锁，进行commit时转为持有读锁。show slave status只使用读锁。</p>

<p>只是臆测下解决方法，待<a href="http://bugs.mysql.com/bug.php?id=70307">bug #70307</a>修掉时再学习。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mysql 5.6.12 master上flush logs在slave上产生两个relay-log]]></title>
    <link href="http://ikarishinjieva.github.com/blog/blog/2013/10/22/mysql-flush-logs-make-two-relay-log-file/"/>
    <updated>2013-10-22T21:42:00+08:00</updated>
    <id>http://ikarishinjieva.github.com/blog/blog/2013/10/22/mysql-flush-logs-make-two-relay-log-file</id>
    <content type="html"><![CDATA[<h2>现象</h2>

<p>一个碰巧观察到的有趣的现象：mysql 5.6.12 在master上flush logs，在slave上会观察到两个新的relay-log file</p>

<p>举例：</p>

<p>slave-relay-bin.000092</p>

<pre><code> FD event
 Rotate to mysql-bin.000056
 Rotate to slave-relay-bin.000093
</code></pre>

<p>slave-relay-bin.000093</p>

<pre><code> FD event slave
 Rotate to mysql-bin.000056
 FD event master
 bla bla…
</code></pre>

<p>可以看到000092这个relay log相当多余。这个现象并不会影响replication的正确性，只是让有强迫症的人有点狂躁</p>

<h2>探索</h2>

<p>在master上net_serv.cc:my_net_write打断点，可以观察到master的确发出了以下三个事件</p>

<ul>
<li>ROTATE_EVENT</li>
</ul>


<p>backtrace</p>

<pre><code>#0  my_net_write (net=0x1ea2858, packet=0x7fffa4002b70 "", len=48)
    at /home/vagrant/mysql-5.6.12/sql/net_serv.cc:284
#1  0x0000000000a48b05 in mysql_binlog_send (thd=0x1ea2600, log_ident=0x7fffa4004c60 "mysql-bin.000052", pos=167,
    slave_gtid_executed=0x0) at /home/vagrant/mysql-5.6.12/sql/rpl_master.cc:1336
#2  0x0000000000a46ad2 in com_binlog_dump (thd=0x1ea2600, packet=0x1ea5d21 "", packet_length=26)
    at /home/vagrant/mysql-5.6.12/sql/rpl_master.cc:746
#3  0x00000000007d1ab9 in dispatch_command (command=COM_BINLOG_DUMP, thd=0x1ea2600, packet=0x1ea5d21 "",
    packet_length=26) at /home/vagrant/mysql-5.6.12/sql/sql_parse.cc:1534
#4  0x00000000007d017b in do_command (thd=0x1ea2600) at /home/vagrant/mysql-5.6.12/sql/sql_parse.cc:1036
#5  0x0000000000797a08 in do_handle_one_connection (thd_arg=0x1ea2600)
    at /home/vagrant/mysql-5.6.12/sql/sql_connect.cc:977
#6  0x00000000007974e4 in handle_one_connection (arg=0x1ea2600)
    at /home/vagrant/mysql-5.6.12/sql/sql_connect.cc:893
#7  0x0000000000aea87a in pfs_spawn_thread (arg=0x1e7aa80)
    at /home/vagrant/mysql-5.6.12/storage/perfschema/pfs.cc:1855
#8  0x00007ffff7bc7851 in start_thread () from /lib64/libpthread.so.0
#9  0x00007ffff6b3290d in clone () from /lib64/libc.so.6
</code></pre>

<ul>
<li>第二个ROTATE_EVENT</li>
</ul>


<p>backtrace</p>

<pre><code>#0  my_net_write (net=0x1ea2858, packet=0x7fffa4002ab0 "", len=48)
    at /home/vagrant/mysql-5.6.12/sql/net_serv.cc:284
#1  0x0000000000a45f04 in fake_rotate_event (net=0x1ea2858, packet=0x1ea2be8,
    log_file_name=0x7fffc94ff270 "./mysql-bin.000056", position=4, errmsg=0x7fffc94ffdb0,
    checksum_alg_arg=1 '\001') at /home/vagrant/mysql-5.6.12/sql/rpl_master.cc:395
#2  0x0000000000a4a33d in mysql_binlog_send (thd=0x1ea2600, log_ident=0x7fffa4004c60 "mysql-bin.000052", pos=167,
    slave_gtid_executed=0x0) at /home/vagrant/mysql-5.6.12/sql/rpl_master.cc:1728
#3  0x0000000000a46ad2 in com_binlog_dump (thd=0x1ea2600, packet=0x1ea5d21 "", packet_length=26)
    at /home/vagrant/mysql-5.6.12/sql/rpl_master.cc:746
#4  0x00000000007d1ab9 in dispatch_command (command=COM_BINLOG_DUMP, thd=0x1ea2600, packet=0x1ea5d21 "",
    packet_length=26) at /home/vagrant/mysql-5.6.12/sql/sql_parse.cc:1534
#5  0x00000000007d017b in do_command (thd=0x1ea2600) at /home/vagrant/mysql-5.6.12/sql/sql_parse.cc:1036
#6  0x0000000000797a08 in do_handle_one_connection (thd_arg=0x1ea2600)
    at /home/vagrant/mysql-5.6.12/sql/sql_connect.cc:977
#7  0x00000000007974e4 in handle_one_connection (arg=0x1ea2600)
    at /home/vagrant/mysql-5.6.12/sql/sql_connect.cc:893
#8  0x0000000000aea87a in pfs_spawn_thread (arg=0x1e7aa80)
    at /home/vagrant/mysql-5.6.12/storage/perfschema/pfs.cc:1855
#9  0x00007ffff7bc7851 in start_thread () from /lib64/libpthread.so.0
#10 0x00007ffff6b3290d in clone () from /lib64/libc.so.6
</code></pre>

<ul>
<li>FORMAT_DESCRIPTION_EVENT</li>
</ul>


<p>可以看到第一个ROTATE_EVENT是由flush logs发出的，第二个ROTATE_EVENT是fake_rotate_event</p>

<h2>关于fake_rotate_event</h2>

<p>以前也<a href="http://ikarishinjieva.github.io/blog/blog/2013/10/16/mysql-mysql_binlog_send-src/">吐槽</a>过fake_rotate_event</p>

<p>master在binlog切换时（不一定是手工flush，也可能是重启，或者容量达到限制）一定要多发一个rotate event，原因如源码rpl_master.cc:mysql_binlog_send中的注释</p>

<pre><code>  /*
    Call fake_rotate_event() in case the previous log (the one which
    we have just finished reading) did not contain a Rotate event.
    There are at least two cases when this can happen:

    - The previous binary log was the last one before the master was
      shutdown and restarted.

    - The previous binary log was GTID-free (did not contain a
      Previous_gtids_log_event) and the slave is connecting using
      the GTID protocol.

    This way we tell the slave about the new log's name and
    position.  If the binlog is 5.0 or later, the next event we
    are going to read and send is Format_description_log_event.
  */
  if ((file=open_binlog_file(&amp;log, log_file_name, &amp;errmsg)) &lt; 0 ||
      fake_rotate_event(net, packet, log_file_name, BIN_LOG_HEADER_SIZE,
                        &amp;errmsg, current_checksum_alg))
</code></pre>

<p>主要是解决之前没有rotate event发送的场景</p>

<p>虽然非常想吐槽，但是我也想不出更好的办法</p>
]]></content>
  </entry>
  
</feed>
